{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ LIBRARIES ###############\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import tsfresh\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh import extract_relevant_features\n",
    "from tsfresh import select_features\n",
    "\n",
    "\n",
    "# Regressors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost.sklearn import XGBRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "epslon = 0.00005\n",
    "\n",
    "\n",
    "def pbe(y_true, y_pred):\n",
    "  if np.sum(y_true)!=0:\n",
    "    return 100*(np.sum(y_pred - y_true)/np.sum(y_true))\n",
    "  else:\n",
    "   return 100*(np.sum(y_pred - y_true)/(np.sum(y_true)+ epslon))  \n",
    "\n",
    "def pocid(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    D = [1 if (y_pred[i] - y_pred[i-1]) * (y_true[i] - y_true[i-1]) > 0 else 0 for i in range(1, n)]\n",
    "    POCID = 100 * np.sum(D) / n\n",
    "    return POCID\n",
    "\n",
    "def znorm(x):\n",
    "    mean = np.mean(x)\n",
    "    std_dev = np.std(x)\n",
    "    # if std_dev != 0:\n",
    "    x_znorm = (x - mean) / std_dev\n",
    "    # else:\n",
    "        # x_znorm = (x - mean) / (std_dev + np.finfo(np.float32).eps)\n",
    "    return x_znorm\n",
    "\n",
    "\n",
    "def get_stats_norm(series, horizon, window):\n",
    "  last_subsequence = series[-(horizon+window):-horizon].values\n",
    "  last_mean = np.mean(last_subsequence)\n",
    "  last_std = np.std(last_subsequence)\n",
    "  return last_mean, last_std\n",
    "\n",
    "# Para predição de vendas por UF (mensal), será considerado horizon = 12\n",
    "# Para predição de vendas por município (anual), será considerado horizon = 1\n",
    "def train_test_split(data, horizon):\n",
    "  X = data.iloc[:,:-1] # features\n",
    "  y = data.iloc[:,-1] # target\n",
    "\n",
    "  X_train = X[:-horizon] # features train\n",
    "  X_test =  X[-horizon:] # features test\n",
    "\n",
    "  y_train = y[:-horizon] # target train\n",
    "  y_test = y[-horizon:] # target test\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "def recursive_multistep_forecasting(X_test, model, horizon):\n",
    "  # example é composto pelas últimas observações vistas\n",
    "  # na prática, é o pbeprimeiro exemplo do conjunto de teste\n",
    "  example = X_test.iloc[0].values.reshape(1,-1)\n",
    "\n",
    "  preds = []\n",
    "  for i in range(horizon):\n",
    "    pred = model.predict(example)[0]\n",
    "    preds.append(pred)\n",
    "\n",
    "    # Descartar o valor da primeira posição do vetor de características\n",
    "    example = example[:,1:]\n",
    "\n",
    "    # Adicionar o valor predito na última posição do vetor de características\n",
    "    example = np.append(example, pred)\n",
    "    example = example.reshape(1,-1)\n",
    "  return preds\n",
    "\n",
    "\n",
    "\n",
    "def rolling_window_real(series, window):\n",
    "  data = []\n",
    "  for i in range(len(series)-window):\n",
    "    # example = znorm(np.array(series[i:i+window+1]))\n",
    "    example = np.array(series[i:i+window+1])\n",
    "    data.append(example)\n",
    "  df = pd.DataFrame(data)\n",
    "  return df\n",
    "\n",
    "\n",
    "def rolling_window(series, window):\n",
    "  data = []\n",
    "  for i in range(len(series)-window):\n",
    "    example = znorm(np.array(series[i:i+window+1]))\n",
    "    data.append(example)\n",
    "  df = pd.DataFrame(data)\n",
    "  return df\n",
    "\n",
    "\n",
    "#função para desnormatização\n",
    "def znorm_reverse(x, mean_x, std_x):\n",
    "  x_denormalized = (np.array(x) * std_x) + mean_x\n",
    "  return x_denormalized\n",
    "\n",
    "def get_stats_norm(series, horizon, window):\n",
    "  last_subsequence = series[-(horizon+window):-horizon].values\n",
    "  last_mean = np.mean(last_subsequence)\n",
    "  last_std = np.std(last_subsequence)\n",
    "  return last_mean, last_std\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def slope(x): return (x[-1] - x[0]) / x[0] if x[0] else 0\n",
    "def abs_diff_mean(x): return np.mean(np.abs(x[1:] - x[:-1])) if len(x) > 1 else 0\n",
    "def diff_std(x): return np.std(x[1:] - x[:-1]) if len(x) > 1 else 0\n",
    "\n",
    "\n",
    "\n",
    "def targeted_forecasting(X_test, model):\n",
    "  # example é composto pelas últimas observações vistas\n",
    "  # na prática, é o pbeprimeiro exemplo do conjunto de teste\n",
    "  example = X_test.iloc[0].values.reshape(1,-1)\n",
    "\n",
    "  preds = []\n",
    "  for i in range(1):\n",
    "    pred = model.predict(example)[0]\n",
    "    preds.append(pred)\n",
    "\n",
    "    # Descartar o valor da primeira posição do vetor de características\n",
    "    example = example[:,1:]\n",
    "\n",
    "    # Adicionar o valor predito na última posição do vetor de características\n",
    "    example = np.append(example, pred)\n",
    "    example = example.reshape(1,-1)\n",
    "  return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### DEFs ##############\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import tsflex\n",
    "from tsflex.features import FeatureDescriptor, FeatureCollection, FuncWrapper\n",
    "import csv\n",
    "\n",
    "\n",
    "\n",
    "def extract_estado(file_name):\n",
    "    parts = file_name.split('_')\n",
    "    estado = parts[1]\n",
    "    return estado\n",
    "\n",
    "def read_csv_files(folder_path):\n",
    "    estados = []\n",
    "    files = os.listdir(folder_path)\n",
    "    for file_name in files:\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'r', newline='') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                headers = next(reader)\n",
    "                estado = extract_estado(file_name)\n",
    "                estados.append(estado)\n",
    "                estados.sort()\n",
    "    return estados\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################################\n",
    "\n",
    "## 36 = 1095.75D\n",
    "## 24 = 730.5D\n",
    "## 12 = 365.25D\n",
    "\n",
    "feature_descriptor_skew_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=ss.skew, output_names=\"skew\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_max_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=np.max, output_names=\"max\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_mediam_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=np.median, output_names=\"mediam\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_min_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=np.min, output_names=\"min\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_var_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=np.var, output_names=\"var\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_std_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=np.std, output_names=\"std\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_entropy_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=ss.entropy, output_names=\"entropy\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_kurtosis_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=ss.kurtosis, output_names=\"kurtosis\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_mean_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=np.mean, output_names=\"mean\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_median_abs_deviation_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=ss.median_abs_deviation, output_names=\"median_abs_deviation\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_sum_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=sum, output_names=\"sum\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_slope_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=slope, output_names=\"slope\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_abs_diff_mean_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=abs_diff_mean, output_names=\"abs_diff_mean\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "feature_descriptor_diff_std_TMP = FeatureDescriptor(\n",
    "    function=FuncWrapper(func=diff_std, output_names=\"diff_std\"),\n",
    "    series_name=\"TMP\", \n",
    "    window=\"730.5D\", stride=\"31D\"\n",
    ")\n",
    "\n",
    "fc = FeatureCollection(feature_descriptors=[\n",
    "    feature_descriptor_skew_TMP,\n",
    "    feature_descriptor_max_TMP,\n",
    "    feature_descriptor_mediam_TMP,\n",
    "    feature_descriptor_min_TMP,\n",
    "    # feature_descriptor_var_TMP,\n",
    "    feature_descriptor_std_TMP,\n",
    "    # feature_descriptor_entropy_TMP,\n",
    "    feature_descriptor_kurtosis_TMP,\n",
    "    feature_descriptor_mean_TMP,\n",
    "    feature_descriptor_median_abs_deviation_TMP,\n",
    "    feature_descriptor_sum_TMP,\n",
    "    feature_descriptor_slope_TMP,\n",
    "    feature_descriptor_abs_diff_mean_TMP,\n",
    "    feature_descriptor_diff_std_TMP\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################\n",
    "\n",
    "\n",
    "def recursive_multistep_forecasting_TsFlexN(series, model, horizon, window):\n",
    "\n",
    "    serieatu=series[:-horizon]\n",
    "    seriec = serieatu.tail(2+window).reset_index(drop=True)\n",
    "    mean_norm, std_norm = get_stats_norm(series['m3'], horizon, window)\n",
    "    predsreal = []\n",
    "\n",
    "    for i in range(horizon):\n",
    "        df2 = seriec\n",
    "        try:\n",
    "            df2['timestamp'] = pd.to_datetime(df2['timestamp'], format='%Y%m')\n",
    "        except Exception as e:\n",
    "            print(\"Error parsing 'timestamp' column:\", e)\n",
    "            raise\n",
    "        if 'm3' not in df2.columns:\n",
    "            raise ValueError(\"'m3' column not found in the CSV file. Columns available: {}\".format(df.columns))\n",
    "        df2 = df2.set_index('timestamp')\n",
    "        df2 = df2.rename(columns={'m3': 'TMP'})\n",
    "        example = np.array(seriec)\n",
    "        new_elements = fc.calculate(data=df2, return_df=True)\n",
    "        exemple_feature = znorm(new_elements.values)\n",
    "        exemple_feature_df = pd.DataFrame(exemple_feature)\n",
    "        exemple_feature_df.fillna(0, inplace=True)\n",
    "        predn = model.predict(exemple_feature_df)\n",
    "        pred = znorm_reverse(predn, mean_norm, std_norm)\n",
    "        predsreal.append(pred)\n",
    "        series2 = seriec.drop(seriec.index[0])\n",
    "\n",
    "        last_timestamp = pd.to_datetime(series2['timestamp'].iloc[-1])\n",
    "\n",
    "        year = last_timestamp.year\n",
    "        month = last_timestamp.month\n",
    "\n",
    "        if month == 12:\n",
    "            next_year = year + 1\n",
    "            next_month = 1\n",
    "        else:\n",
    "            next_year = year\n",
    "            next_month = month + 1\n",
    "\n",
    "        next_timestamp = pd.Timestamp(year=next_year, month=next_month, day=1)\n",
    "        new_row = pd.DataFrame({'timestamp': [next_timestamp], 'm3': pred})\n",
    "        seriec = pd.concat([series2, new_row], ignore_index=True)\n",
    "\n",
    "    return predsreal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 150\u001b[0m\n\u001b[0;32m    127\u001b[0m feature_descriptor_diff_std_TMP \u001b[38;5;241m=\u001b[39m FeatureDescriptor(\n\u001b[0;32m    128\u001b[0m     function\u001b[38;5;241m=\u001b[39mFuncWrapper(func\u001b[38;5;241m=\u001b[39mdiff_std, output_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiff_std\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    129\u001b[0m     series_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTMP\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m    130\u001b[0m     window\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m365.25D\u001b[39m\u001b[38;5;124m\"\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m31D\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    131\u001b[0m )\n\u001b[0;32m    133\u001b[0m fc \u001b[38;5;241m=\u001b[39m FeatureCollection(feature_descriptors\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m    134\u001b[0m     feature_descriptor_skew_TMP,\n\u001b[0;32m    135\u001b[0m     feature_descriptor_max_TMP,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m     feature_descriptor_diff_std_TMP\n\u001b[0;32m    148\u001b[0m ])\n\u001b[1;32m--> 150\u001b[0m result_df \u001b[38;5;241m=\u001b[39m \u001b[43mfc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    152\u001b[0m result_df\u001b[38;5;241m.\u001b[39mreset_index(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    154\u001b[0m folder_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTsFlex\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tsflex\\features\\feature_collection.py:1254\u001b[0m, in \u001b[0;36mFeatureCollection.calculate\u001b[1;34m(self, data, stride, segment_start_idxs, segment_end_idxs, return_df, window_idx, include_final_window, group_by_all, group_by_consecutive, bound_method, approve_sparsity, show_progress, logging_file_path, n_jobs)\u001b[0m\n\u001b[0;32m   1241\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m get_stroll_func\n\u001b[0;32m   1242\u001b[0m get_stroll_func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stroll_feat_generator(\n\u001b[0;32m   1243\u001b[0m     series_dict,\n\u001b[0;32m   1244\u001b[0m     calc_stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     approve_sparsity\u001b[38;5;241m=\u001b[39mapprove_sparsity,\n\u001b[0;32m   1252\u001b[0m )\n\u001b[1;32m-> 1254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_calculate_feature_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_executor_stroll\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort_output_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tsflex\\features\\feature_collection.py:796\u001b[0m, in \u001b[0;36mFeatureCollection._calculate_feature_list\u001b[1;34m(self, executor, n_jobs, show_progress, return_df, sort_output_index, f_handler)\u001b[0m\n\u001b[0;32m    794\u001b[0m     idxs \u001b[38;5;241m=\u001b[39m tqdm(idxs)\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 796\u001b[0m     calculated_feature_list \u001b[38;5;241m=\u001b[39m [\u001b[43mexecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m idxs]\n\u001b[0;32m    797\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m    798\u001b[0m     traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tsflex\\features\\feature_collection.py:293\u001b[0m, in \u001b[0;36mFeatureCollection._executor_stroll\u001b[1;34m(idx)\u001b[0m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;66;03m# Uses the global get_stroll_func\u001b[39;00m\n\u001b[0;32m    292\u001b[0m stroll, function \u001b[38;5;241m=\u001b[39m get_stroll_func(idx)\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mstroll\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tsflex\\features\\segmenter\\strided_rolling.py:454\u001b[0m, in \u001b[0;36mStridedRolling.apply_func\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    449\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT \u001b[38;5;28;01mif\u001b[39;00m out_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    452\u001b[0m     \u001b[38;5;66;03m# Function execution over slices (default)\u001b[39;00m\n\u001b[0;32m    453\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\n\u001b[1;32m--> 454\u001b[0m         \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m                        \u001b[49m\u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_indexes\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_indexes\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m                    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseries_containers\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m                \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    466\u001b[0m     )\n\u001b[0;32m    468\u001b[0m \u001b[38;5;66;03m# Check if the function output is valid.\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;66;03m# This assertion will be raised when e.g. np.max is applied vectorized without\u001b[39;00m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;66;03m# specifying axis=1.\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m out\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVectorized function returned only 1 (non-array) value!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tsflex\\features\\function_wrapper.py:141\u001b[0m, in \u001b[0;36mFuncWrapper.__call__\u001b[1;34m(self, *series)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mseries: Union[np\u001b[38;5;241m.\u001b[39mndarray, pd\u001b[38;5;241m.\u001b[39mSeries]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    128\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call wrapped function with passed data.\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \n\u001b[0;32m    130\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m \n\u001b[0;32m    140\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:483\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    481\u001b[0m     samples \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(sample\u001b[38;5;241m.\u001b[39mravel()) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m samples]\n\u001b[0;32m    482\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m     samples \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m     axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39matleast_1d(axis)\n\u001b[0;32m    485\u001b[0m     n_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(axis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:18\u001b[0m, in \u001b[0;36m_broadcast_arrays\u001b[1;34m(arrays, axis)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_broadcast_arrays\u001b[39m(arrays, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    Broadcast shapes of arrays, ignoring incompatibility of specified axes\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     new_shapes \u001b[38;5;241m=\u001b[39m \u001b[43m_broadcast_array_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     20\u001b[0m         new_shapes \u001b[38;5;241m=\u001b[39m [new_shapes]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(arrays)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:30\u001b[0m, in \u001b[0;36m_broadcast_array_shapes\u001b[1;34m(arrays, axis)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03mBroadcast shapes of arrays, ignoring incompatibility of specified axes\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     29\u001b[0m shapes \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39masarray(arr)\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_broadcast_shapes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\scipy\\stats\\_axis_nan_policy.py:68\u001b[0m, in \u001b[0;36m_broadcast_shapes\u001b[1;34m(shapes, axis)\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m AxisError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`axis` must contain only distinct elements\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     67\u001b[0m     removed_shapes \u001b[38;5;241m=\u001b[39m new_shapes[:, axis]\n\u001b[1;32m---> 68\u001b[0m     new_shapes \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdelete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;66;03m# If arrays are broadcastable, shape elements that are 1 may be replaced\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# with a corresponding non-1 shape element. Assuming arrays are\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# broadcastable, that final shape element can be found with:\u001b[39;00m\n\u001b[0;32m     73\u001b[0m new_shape \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(new_shapes, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\numpy\\lib\\function_base.py:5339\u001b[0m, in \u001b[0;36mdelete\u001b[1;34m(arr, obj, axis)\u001b[0m\n\u001b[0;32m   5337\u001b[0m slobj[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, obj)\n\u001b[0;32m   5338\u001b[0m new[\u001b[38;5;28mtuple\u001b[39m(slobj)] \u001b[38;5;241m=\u001b[39m arr[\u001b[38;5;28mtuple\u001b[39m(slobj)]\n\u001b[1;32m-> 5339\u001b[0m slobj[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mslice\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   5340\u001b[0m slobj2 \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mslice\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)]\u001b[38;5;241m*\u001b[39mndim\n\u001b[0;32m   5341\u001b[0m slobj2[axis] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(obj\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "######### TsFlex SAVE #################\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import tsflex\n",
    "from tsflex.features import FeatureDescriptor, FeatureCollection, FuncWrapper\n",
    "\n",
    "\n",
    "products = sorted([name for name in os.listdir('./uf/') if os.path.isdir(os.path.join('./uf/', name))])\n",
    "\n",
    "horizon = 12\n",
    "window = 12\n",
    "\n",
    "for product in products:\n",
    "    folder_path = f'./uf/{product}/'\n",
    "    # Read the CSV files and extract estado names\n",
    "    estados = read_csv_files(folder_path)\n",
    "    \n",
    "    for estado in estados:\n",
    "    \n",
    "        df = pd.read_csv(f\"./uf/{product}/mensal_{estado}_{product}.csv\", header=0, sep=\";\")\n",
    "\n",
    "        series = df\n",
    "\n",
    "        ###############################################################\n",
    "\n",
    "        try:\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y%m')\n",
    "        except Exception as e:\n",
    "            print(\"Error parsing 'timestamp' column:\", e)\n",
    "            raise\n",
    "\n",
    "        if 'm3' not in df.columns:\n",
    "            raise ValueError(\"'m3' column not found in the CSV file. Columns available: {}\".format(df.columns))\n",
    "\n",
    "        df = df.set_index('timestamp')\n",
    "\n",
    "        df = df.rename(columns={'m3': 'TMP'})\n",
    "\n",
    "\n",
    "        ## 36 = 1095.75D\n",
    "\n",
    "        ## 12 = 365.25\n",
    "\n",
    "        feature_descriptor_skew_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=ss.skew, output_names=\"skew\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_max_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=np.max, output_names=\"max\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_mediam_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=np.median, output_names=\"mediam\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_min_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=np.min, output_names=\"min\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_var_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=np.var, output_names=\"var\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_std_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=np.std, output_names=\"std\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_entropy_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=ss.entropy, output_names=\"entropy\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_kurtosis_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=ss.kurtosis, output_names=\"kurtosis\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_mean_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=np.mean, output_names=\"mean\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_median_abs_deviation_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=ss.median_abs_deviation, output_names=\"median_abs_deviation\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_sum_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=sum, output_names=\"sum\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_slope_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=slope, output_names=\"slope\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_abs_diff_mean_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=abs_diff_mean, output_names=\"abs_diff_mean\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        feature_descriptor_diff_std_TMP = FeatureDescriptor(\n",
    "            function=FuncWrapper(func=diff_std, output_names=\"diff_std\"),\n",
    "            series_name=\"TMP\", \n",
    "            window=\"365.25D\", stride=\"31D\"\n",
    "        )\n",
    "\n",
    "        fc = FeatureCollection(feature_descriptors=[\n",
    "            feature_descriptor_skew_TMP,\n",
    "            feature_descriptor_max_TMP,\n",
    "            feature_descriptor_mediam_TMP,\n",
    "            feature_descriptor_min_TMP,\n",
    "            # feature_descriptor_var_TMP,\n",
    "            feature_descriptor_std_TMP,\n",
    "            # feature_descriptor_entropy_TMP,\n",
    "            feature_descriptor_kurtosis_TMP,\n",
    "            feature_descriptor_mean_TMP,\n",
    "            feature_descriptor_median_abs_deviation_TMP,\n",
    "            feature_descriptor_sum_TMP,\n",
    "            feature_descriptor_slope_TMP,\n",
    "            feature_descriptor_abs_diff_mean_TMP,\n",
    "            feature_descriptor_diff_std_TMP\n",
    "        ])\n",
    "\n",
    "        result_df = fc.calculate(data=df, return_df=True)\n",
    "\n",
    "        result_df.reset_index(inplace=True)\n",
    "\n",
    "        folder_name = 'TsFlex'\n",
    "        if not os.path.exists(folder_name):\n",
    "            os.makedirs(folder_name)\n",
    "        \n",
    "        result_df.to_csv(f'{folder_name}/FEAT_TsFresh_{product}_{window}_{estado}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### TsFlex TEST #################\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import tsflex\n",
    "from tsflex.features import FeatureDescriptor, FeatureCollection, FuncWrapper\n",
    "\n",
    "horizon = 12\n",
    "window = 24\n",
    "\n",
    "\n",
    "product = 'etanolhidratado'\n",
    "estado = 'ac'\n",
    "\n",
    "\n",
    "# products = sorted([name for name in os.listdir('./uf/') if os.path.isdir(os.path.join('./uf/', name))])\n",
    "# for product in products:\n",
    "#     folder_path = f'./uf/{product}/'\n",
    "#     # Read the CSV files and extract estado names\n",
    "#     estados = read_csv_files(folder_path)\n",
    "    \n",
    "#     for estado in estados:\n",
    "\n",
    "df = pd.read_csv(f\"./uf/{product}/mensal_{estado}_{product}.csv\", header=0, sep=\";\")\n",
    "\n",
    "series = df\n",
    "\n",
    "###############################################################\n",
    "\n",
    "try:\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y%m')\n",
    "except Exception as e:\n",
    "    print(\"Error parsing 'timestamp' column:\", e)\n",
    "    raise\n",
    "\n",
    "if 'm3' not in df.columns:\n",
    "    raise ValueError(\"'m3' column not found in the CSV file. Columns available: {}\".format(df.columns))\n",
    "\n",
    "df = df.set_index('timestamp')\n",
    "df = df.rename(columns={'m3': 'TMP'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "result_df = fc.calculate(data=df, return_df=True)\n",
    "result_df.reset_index(inplace=True)\n",
    "\n",
    "result_df_timestamp = result_df[result_df.columns[0]]\n",
    "result_df = result_df.drop(result_df.columns[0], axis=1)\n",
    "result_df_norm = result_df.apply(znorm, axis=1)\n",
    "\n",
    "y_norm = rolling_window(series['m3'],window)\n",
    "\n",
    "result_df_norm['y'] = y_norm[window]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(result_df_norm, horizon)\n",
    "\n",
    "\n",
    "\n",
    "############## Regressores ##################\n",
    "\n",
    "regr1 = LinearRegression()\n",
    "regr2 = KNeighborsRegressor(n_neighbors = 3)\n",
    "regr3 = XGBRegressor()\n",
    "regr4 = SVR(kernel='rbf')\n",
    "regr5 = RandomForestRegressor()\n",
    "regr6 = MLPRegressor(random_state=1, activation='relu', max_iter=500)\n",
    "\n",
    "\n",
    "X_train.columns = range(0, len(X_train.columns))\n",
    "\n",
    "regr1.fit(X_train, y_train)\n",
    "predictions1a = recursive_multistep_forecasting_TsFlexN(series, regr1, horizon, window)\n",
    "predictions1a = [a.flatten()[0] for a in predictions1a]\n",
    "\n",
    "regr2.fit(X_train, y_train)\n",
    "predictions2a = recursive_multistep_forecasting_TsFlexN(series, regr2, horizon, window)\n",
    "predictions2a = [a.flatten()[0] for a in predictions2a]\n",
    "\n",
    "regr3.fit(X_train, y_train)\n",
    "predictions3a = recursive_multistep_forecasting_TsFlexN(series, regr3, horizon, window)\n",
    "predictions3a = [a.flatten()[0] for a in predictions3a]\n",
    "\n",
    "\n",
    "regr4.fit(X_train, y_train)\n",
    "predictions4a = recursive_multistep_forecasting_TsFlexN(series, regr4, horizon, window)\n",
    "predictions4a = [a.flatten()[0] for a in predictions4a]\n",
    "\n",
    "regr5.fit(X_train, y_train)\n",
    "predictions5a = recursive_multistep_forecasting_TsFlexN(series, regr5, horizon, window)\n",
    "predictions5a = [a.flatten()[0] for a in predictions5a]\n",
    "\n",
    "regr6.fit(X_train, y_train)\n",
    "predictions6a = recursive_multistep_forecasting_TsFlexN(series, regr6, horizon, window)\n",
    "predictions6a = [a.flatten()[0] for a in predictions6a]\n",
    "\n",
    "\n",
    "Valores_Reais = series['m3'].tail(horizon)\n",
    "Valores_Reais = Valores_Reais.reset_index(drop=True)\n",
    "\n",
    "mape_result1 = mape(Valores_Reais, predictions1a)\n",
    "mape_result2 = mape(Valores_Reais, predictions2a)\n",
    "mape_result3 = mape(Valores_Reais, predictions3a)\n",
    "mape_result4 = mape(Valores_Reais, predictions4a)\n",
    "mape_result5 = mape(Valores_Reais, predictions5a)\n",
    "mape_result6 = mape(Valores_Reais, predictions6a)\n",
    "\n",
    "pbe_result1 = pbe(Valores_Reais, predictions1a)\n",
    "pbe_result2 = pbe(Valores_Reais, predictions2a)\n",
    "pbe_result3 = pbe(Valores_Reais, predictions3a)\n",
    "pbe_result4 = pbe(Valores_Reais, predictions4a)\n",
    "pbe_result5 = pbe(Valores_Reais, predictions5a)\n",
    "pbe_result6 = pbe(Valores_Reais, predictions6a)\n",
    "\n",
    "pocid_result1 = pocid(Valores_Reais, predictions1a)\n",
    "pocid_result2 = pocid(Valores_Reais, predictions2a)\n",
    "pocid_result3 = pocid(Valores_Reais, predictions3a)\n",
    "pocid_result4 = pocid(Valores_Reais, predictions4a)\n",
    "pocid_result5 = pocid(Valores_Reais, predictions5a)\n",
    "pocid_result6 = pocid(Valores_Reais, predictions6a)\n",
    "\n",
    "predictions1b = ', '.join(f\"{item:f}\" for item in predictions1a)\n",
    "predictions2b = ', '.join(f\"{item:f}\" for item in predictions2a)\n",
    "predictions3b = ', '.join(f\"{item:f}\" for item in predictions3a)\n",
    "predictions4b = ', '.join(f\"{item:f}\" for item in predictions4a)\n",
    "predictions5b = ', '.join(f\"{item:f}\" for item in predictions5a)\n",
    "predictions6b = ', '.join(f\"{item:f}\" for item in predictions6a)\n",
    "    \n",
    "rows_data = [\n",
    "    [product,estado,'LR',mape_result1,pocid_result1,pbe_result1,predictions1b],\n",
    "    [product,estado,'kNN',mape_result2,pocid_result2,pbe_result2,predictions2b],\n",
    "    [product,estado,'XGB',mape_result3,pocid_result3,pbe_result3,predictions3b],\n",
    "    [product,estado,'SVR',mape_result4,pocid_result4,pbe_result4,predictions4b],\n",
    "    [product,estado,'RF',mape_result5,pocid_result5,pbe_result5,predictions5b],\n",
    "    [product,estado,'MLP',mape_result6,pocid_result6,pbe_result6,predictions6b],          \n",
    "]\n",
    "\n",
    "# # Salva Modelos\n",
    "# folder_path = f\"./00-MODELS_UF_MENSAL-TsFel/\"\n",
    "# os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# with open(os.path.join(folder_path, f'TsFel_LR_{product}_{estado}_{window}_model.pkl'), 'wb') as fd1:\n",
    "#     pickle.dump(regr2, fd1)\n",
    "# with open(os.path.join(folder_path, f'TsFel_KNN_{product}_{estado}_{window}_model.pkl'), 'wb') as fd2:\n",
    "#     pickle.dump(regr2, fd2)\n",
    "# with open(os.path.join(folder_path, f'TsFel_XGB_{product}_{estado}_{window}_model.pkl'), 'wb') as fd3:\n",
    "#     pickle.dump(regr3, fd3)\n",
    "# with open(os.path.join(folder_path, f'TsFel_SVR_{product}_{estado}_{window}_model.pkl'), 'wb') as fd4:\n",
    "#     pickle.dump(regr4, fd4)\n",
    "# with open(os.path.join(folder_path, f'TsFel_RF_{product}_{estado}_{window}_model.pkl'), 'wb') as fd5:\n",
    "#     pickle.dump(regr5, fd5)\n",
    "# with open(os.path.join(folder_path, f'TsFel_MLP_{product}_{estado}_{window}_model.pkl'), 'wb') as fd6:\n",
    "#     pickle.dump(regr2, fd6)\n",
    "\n",
    "# CSV Output VALORES REAIS\n",
    "with open(f'TsFlex_{window}_Norm_output.csv', 'a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    for row_data in rows_data:\n",
    "        writer.writerow(row_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### TsFlex AUTO NORM #################\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import tsflex\n",
    "from tsflex.features import FeatureDescriptor, FeatureCollection, FuncWrapper\n",
    "\n",
    "horizon = 12\n",
    "window = 24\n",
    "\n",
    "\n",
    "# product = 'etanolhidratado'\n",
    "# estado = 'ac'\n",
    "\n",
    "\n",
    "products = sorted([name for name in os.listdir('./uf/') if os.path.isdir(os.path.join('./uf/', name))])\n",
    "for product in products:\n",
    "    folder_path = f'./uf/{product}/'\n",
    "    # Read the CSV files and extract estado names\n",
    "    estados = read_csv_files(folder_path)\n",
    "    \n",
    "    for estado in estados:\n",
    "\n",
    "        df = pd.read_csv(f\"./uf/{product}/mensal_{estado}_{product}.csv\", header=0, sep=\";\")\n",
    "\n",
    "        series = df\n",
    "\n",
    "        ###############################################################\n",
    "\n",
    "        try:\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], format='%Y%m')\n",
    "        except Exception as e:\n",
    "            print(\"Error parsing 'timestamp' column:\", e)\n",
    "            raise\n",
    "\n",
    "        if 'm3' not in df.columns:\n",
    "            raise ValueError(\"'m3' column not found in the CSV file. Columns available: {}\".format(df.columns))\n",
    "\n",
    "        df = df.set_index('timestamp')\n",
    "        df = df.rename(columns={'m3': 'TMP'})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        result_df = fc.calculate(data=df, return_df=True)\n",
    "        result_df.reset_index(inplace=True)\n",
    "\n",
    "        result_df_timestamp = result_df[result_df.columns[0]]\n",
    "        result_df = result_df.drop(result_df.columns[0], axis=1)\n",
    "        result_df_norm = result_df.apply(znorm, axis=1)\n",
    "        \n",
    "\n",
    "        y_norm = rolling_window(series['m3'],window)\n",
    "\n",
    "        result_df_norm['y'] = y_norm[window]\n",
    "        result_df_norm.fillna(0, inplace=True)\n",
    "\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(result_df_norm, horizon)\n",
    "\n",
    "\n",
    "\n",
    "        ############## Regressores ##################\n",
    "\n",
    "        regr1 = LinearRegression()\n",
    "        regr2 = KNeighborsRegressor(n_neighbors = 3)\n",
    "        regr3 = XGBRegressor()\n",
    "        regr4 = SVR(kernel='rbf')\n",
    "        regr5 = RandomForestRegressor()\n",
    "        regr6 = MLPRegressor(random_state=1, activation='relu', max_iter=500)\n",
    "\n",
    "\n",
    "        X_train.columns = range(0, len(X_train.columns))\n",
    "\n",
    "        regr1.fit(X_train, y_train)\n",
    "        predictions1a = recursive_multistep_forecasting_TsFlexN(series, regr1, horizon, window)\n",
    "        predictions1a = [a.flatten()[0] for a in predictions1a]\n",
    "\n",
    "        regr2.fit(X_train, y_train)\n",
    "        predictions2a = recursive_multistep_forecasting_TsFlexN(series, regr2, horizon, window)\n",
    "        predictions2a = [a.flatten()[0] for a in predictions2a]\n",
    "\n",
    "        regr3.fit(X_train, y_train)\n",
    "        predictions3a = recursive_multistep_forecasting_TsFlexN(series, regr3, horizon, window)\n",
    "        predictions3a = [a.flatten()[0] for a in predictions3a]\n",
    "\n",
    "\n",
    "        regr4.fit(X_train, y_train)\n",
    "        predictions4a = recursive_multistep_forecasting_TsFlexN(series, regr4, horizon, window)\n",
    "        predictions4a = [a.flatten()[0] for a in predictions4a]\n",
    "\n",
    "        regr5.fit(X_train, y_train)\n",
    "        predictions5a = recursive_multistep_forecasting_TsFlexN(series, regr5, horizon, window)\n",
    "        predictions5a = [a.flatten()[0] for a in predictions5a]\n",
    "\n",
    "        regr6.fit(X_train, y_train)\n",
    "        predictions6a = recursive_multistep_forecasting_TsFlexN(series, regr6, horizon, window)\n",
    "        predictions6a = [a.flatten()[0] for a in predictions6a]\n",
    "\n",
    "\n",
    "        Valores_Reais = series['m3'].tail(horizon)\n",
    "        Valores_Reais = Valores_Reais.reset_index(drop=True)\n",
    "\n",
    "        mape_result1 = mape(Valores_Reais, predictions1a)\n",
    "        mape_result2 = mape(Valores_Reais, predictions2a)\n",
    "        mape_result3 = mape(Valores_Reais, predictions3a)\n",
    "        mape_result4 = mape(Valores_Reais, predictions4a)\n",
    "        mape_result5 = mape(Valores_Reais, predictions5a)\n",
    "        mape_result6 = mape(Valores_Reais, predictions6a)\n",
    "\n",
    "        pbe_result1 = pbe(Valores_Reais, predictions1a)\n",
    "        pbe_result2 = pbe(Valores_Reais, predictions2a)\n",
    "        pbe_result3 = pbe(Valores_Reais, predictions3a)\n",
    "        pbe_result4 = pbe(Valores_Reais, predictions4a)\n",
    "        pbe_result5 = pbe(Valores_Reais, predictions5a)\n",
    "        pbe_result6 = pbe(Valores_Reais, predictions6a)\n",
    "\n",
    "        pocid_result1 = pocid(Valores_Reais, predictions1a)\n",
    "        pocid_result2 = pocid(Valores_Reais, predictions2a)\n",
    "        pocid_result3 = pocid(Valores_Reais, predictions3a)\n",
    "        pocid_result4 = pocid(Valores_Reais, predictions4a)\n",
    "        pocid_result5 = pocid(Valores_Reais, predictions5a)\n",
    "        pocid_result6 = pocid(Valores_Reais, predictions6a)\n",
    "\n",
    "        predictions1b = ', '.join(f\"{item:f}\" for item in predictions1a)\n",
    "        predictions2b = ', '.join(f\"{item:f}\" for item in predictions2a)\n",
    "        predictions3b = ', '.join(f\"{item:f}\" for item in predictions3a)\n",
    "        predictions4b = ', '.join(f\"{item:f}\" for item in predictions4a)\n",
    "        predictions5b = ', '.join(f\"{item:f}\" for item in predictions5a)\n",
    "        predictions6b = ', '.join(f\"{item:f}\" for item in predictions6a)\n",
    "            \n",
    "        rows_data = [\n",
    "            [product,estado,'LR',mape_result1,pocid_result1,pbe_result1,predictions1b],\n",
    "            [product,estado,'kNN',mape_result2,pocid_result2,pbe_result2,predictions2b],\n",
    "            [product,estado,'XGB',mape_result3,pocid_result3,pbe_result3,predictions3b],\n",
    "            [product,estado,'SVR',mape_result4,pocid_result4,pbe_result4,predictions4b],\n",
    "            [product,estado,'RF',mape_result5,pocid_result5,pbe_result5,predictions5b],\n",
    "            [product,estado,'MLP',mape_result6,pocid_result6,pbe_result6,predictions6b],          \n",
    "        ]\n",
    "\n",
    "        # # Salva Modelos\n",
    "        # folder_path = f\"./00-MODELS_UF_MENSAL-TsFel/\"\n",
    "        # os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "        # with open(os.path.join(folder_path, f'TsFel_LR_{product}_{estado}_{window}_model.pkl'), 'wb') as fd1:\n",
    "        #     pickle.dump(regr2, fd1)\n",
    "        # with open(os.path.join(folder_path, f'TsFel_KNN_{product}_{estado}_{window}_model.pkl'), 'wb') as fd2:\n",
    "        #     pickle.dump(regr2, fd2)\n",
    "        # with open(os.path.join(folder_path, f'TsFel_XGB_{product}_{estado}_{window}_model.pkl'), 'wb') as fd3:\n",
    "        #     pickle.dump(regr3, fd3)\n",
    "        # with open(os.path.join(folder_path, f'TsFel_SVR_{product}_{estado}_{window}_model.pkl'), 'wb') as fd4:\n",
    "        #     pickle.dump(regr4, fd4)\n",
    "        # with open(os.path.join(folder_path, f'TsFel_RF_{product}_{estado}_{window}_model.pkl'), 'wb') as fd5:\n",
    "        #     pickle.dump(regr5, fd5)\n",
    "        # with open(os.path.join(folder_path, f'TsFel_MLP_{product}_{estado}_{window}_model.pkl'), 'wb') as fd6:\n",
    "        #     pickle.dump(regr2, fd6)\n",
    "\n",
    "        # CSV Output VALORES REAIS\n",
    "        with open(f'TsFlex_{window}_Norm_output.csv', 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row_data in rows_data:\n",
    "                writer.writerow(row_data)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
