{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "############ LOADING ###############\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import pycatch22\n",
    "\n",
    "# Regressors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost.sklearn import XGBRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# variavel que evita NaN nos resultados\n",
    "epslon = 0.00005\n",
    "\n",
    "def pbe(y_true, y_pred):\n",
    "  if np.sum(y_true)!=0:\n",
    "    return 100*(np.sum(y_pred - y_true)/np.sum(y_true))\n",
    "  else:\n",
    "   return 100*(np.sum(y_pred - y_true)/(np.sum(y_true)+ epslon))  \n",
    "\n",
    "def pocid(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    D = [1 if (y_pred[i] - y_pred[i-1]) * (y_true[i] - y_true[i-1]) > 0 else 0 for i in range(1, n)]\n",
    "    POCID = 100 * np.sum(D) / n\n",
    "    return POCID\n",
    "\n",
    "#função para normalização\n",
    "def znorm(x):\n",
    "  if np.std(x)!=0:\n",
    "    x_znorm = (x - np.mean(x)) / np.std(x)\n",
    "  else:\n",
    "    x_znorm = (x - np.mean(x)) / (np.std(x) + epslon) \n",
    "   \n",
    "  return x_znorm\n",
    "\n",
    "#função para desnormatização\n",
    "def znorm_reverse(x, mean_x, std_x):\n",
    "  x_denormalized = (np.array(x) * std_x) + mean_x\n",
    "  return x_denormalized\n",
    "\n",
    "def get_stats_norm(series, horizon, window):\n",
    "  last_subsequence = series[-(horizon+window):-horizon].values\n",
    "  last_mean = np.mean(last_subsequence)\n",
    "  last_std = np.std(last_subsequence)\n",
    "  return last_mean, last_std\n",
    "\n",
    "# Em geral, considera-se um tamanho de janela capaz de capturar um ciclo dos dados\n",
    "# Por exemplo, 12 observações no caso dos dados com frequência mensal\n",
    "def rolling_window(series, window):\n",
    "  data = []\n",
    "  for i in range(len(series)-window):\n",
    "    example = znorm(np.array(series[i:i+window+1]))\n",
    "    data.append(example)\n",
    "  df = pd.DataFrame(data)\n",
    "  return df\n",
    "\n",
    "# Para predição de vendas por UF (mensal), será considerado horizon = 12\n",
    "# Para predição de vendas por município (anual), será considerado horizon = 1\n",
    "def train_test_split(data, horizon):\n",
    "  X = data.iloc[:,:-1] # features\n",
    "  y = data.iloc[:,-1] # target\n",
    "\n",
    "  X_train = X[:-horizon] # features train\n",
    "  X_test =  X[-horizon:] # features test\n",
    "\n",
    "  y_train = y[:-horizon] # target train\n",
    "  y_test = y[-horizon:] # target test\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "def recursive_multistep_forecasting(X_test, model, horizon):\n",
    "  # example é composto pelas últimas observações vistas\n",
    "  # na prática, é o pbeprimeiro exemplo do conjunto de teste\n",
    "  example = X_test.iloc[0].values.reshape(1,-1)\n",
    "\n",
    "  preds = []\n",
    "  for i in range(horizon):\n",
    "    pred = model.predict(example)[0]\n",
    "    preds.append(pred)\n",
    "\n",
    "    # Descartar o valor da primeira posição do vetor de características\n",
    "    example = example[:,1:]\n",
    "\n",
    "    # Adicionar o valor predito na última posição do vetor de características\n",
    "    example = np.append(example, pred)\n",
    "    example = example.reshape(1,-1)\n",
    "  return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#VERIFICAÇÃO DOS ESTADOS \n",
    "\n",
    "def extract_estado(file_name):\n",
    "    # Split the file name by underscores\n",
    "    parts = file_name.split('_')\n",
    "    # Extract the name between underscores\n",
    "    estado = parts[1]\n",
    "    return estado\n",
    "\n",
    "def read_csv_files(folder_path):\n",
    "    estados = []\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Iterate through each file\n",
    "    for file_name in files:\n",
    "        # Check if it's a CSV file\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            # Open the CSV file and read the data\n",
    "            with open(file_path, 'r', newline='') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                # Assuming the first row contains headers\n",
    "                headers = next(reader)\n",
    "                # Extract estado from file name and append to estados list\n",
    "                estado = extract_estado(file_name)\n",
    "                estados.append(estado)\n",
    "                estados.sort()\n",
    "    return estados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon = 12\n",
    "window = 12\n",
    "\n",
    "product ='gasolinac'\n",
    "estado = 'ac'\n",
    "\n",
    "########################################\n",
    "products = sorted([name for name in os.listdir('./uf/') if os.path.isdir(os.path.join('./uf/', name))])\n",
    "\n",
    "folder_path = f'./uf/{product}/'\n",
    "# Read the CSV files and extract estado names\n",
    "estados = read_csv_files(folder_path)\n",
    "\n",
    "# Carregamento do arquivo csv com todas as features\n",
    "df_c = pd.read_csv(f'./concatenate/{product}_{window}_{estado}_concatenated.csv')\n",
    "\n",
    "df_c_ts = df_c.iloc[:, 0]\n",
    "\n",
    "# df_features = df_c.drop(df_c.columns[0], axis=1)\n",
    "\n",
    "df_t = pd.read_csv(f'./uf/{product}/mensal_{estado}_{product}.csv', header=0, sep=\";\")\n",
    "\n",
    "# Exclude the first 24 rows and get the 'm3' column\n",
    "series = df_t['m3']\n",
    "target = rolling_window(series, window)\n",
    "\n",
    "target_norm = target.iloc[:, -1].tail(386).reset_index(drop=True)\n",
    "\n",
    "# Normalization\n",
    "df_c_znorm = df_features.apply(znorm, axis=0)\n",
    "\n",
    "# # # Replace NaN values with 0, if necessary\n",
    "# df_c_znorm.fillna(0, inplace=True)\n",
    "\n",
    "# # Criação do dataframe DATAIN para treino dos regressores\n",
    "df_c_znorm['y'] = target_norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.089124</td>\n",
       "      <td>-0.180325</td>\n",
       "      <td>-0.537766</td>\n",
       "      <td>-1.088421</td>\n",
       "      <td>-0.427138</td>\n",
       "      <td>1.036690</td>\n",
       "      <td>0.699759</td>\n",
       "      <td>-0.877712</td>\n",
       "      <td>1.162002</td>\n",
       "      <td>-0.503236</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088074</td>\n",
       "      <td>0.587693</td>\n",
       "      <td>0.822062</td>\n",
       "      <td>0.307161</td>\n",
       "      <td>0.546479</td>\n",
       "      <td>0.163082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.345343</td>\n",
       "      <td>-0.432183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.413332</td>\n",
       "      <td>0.515227</td>\n",
       "      <td>-0.882033</td>\n",
       "      <td>-1.088421</td>\n",
       "      <td>-1.061257</td>\n",
       "      <td>1.362584</td>\n",
       "      <td>0.699759</td>\n",
       "      <td>-0.877712</td>\n",
       "      <td>-1.379220</td>\n",
       "      <td>-0.503236</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088074</td>\n",
       "      <td>0.587693</td>\n",
       "      <td>1.187075</td>\n",
       "      <td>1.224350</td>\n",
       "      <td>0.546479</td>\n",
       "      <td>0.163082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.345343</td>\n",
       "      <td>-0.729170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.475836</td>\n",
       "      <td>-1.990814</td>\n",
       "      <td>-0.993420</td>\n",
       "      <td>-1.088421</td>\n",
       "      <td>1.235876</td>\n",
       "      <td>1.670966</td>\n",
       "      <td>0.699759</td>\n",
       "      <td>-0.877712</td>\n",
       "      <td>-1.379220</td>\n",
       "      <td>-0.503236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419081</td>\n",
       "      <td>0.587693</td>\n",
       "      <td>1.187075</td>\n",
       "      <td>1.224350</td>\n",
       "      <td>0.546479</td>\n",
       "      <td>0.163082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.345343</td>\n",
       "      <td>-1.331194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.965243</td>\n",
       "      <td>-1.877247</td>\n",
       "      <td>-0.888654</td>\n",
       "      <td>-1.088421</td>\n",
       "      <td>0.362412</td>\n",
       "      <td>1.419465</td>\n",
       "      <td>0.699759</td>\n",
       "      <td>-0.877712</td>\n",
       "      <td>-1.248901</td>\n",
       "      <td>-0.503236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166574</td>\n",
       "      <td>0.587693</td>\n",
       "      <td>-0.145004</td>\n",
       "      <td>1.224350</td>\n",
       "      <td>0.546479</td>\n",
       "      <td>0.163082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.345343</td>\n",
       "      <td>0.373677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.798722</td>\n",
       "      <td>-0.617008</td>\n",
       "      <td>-0.926136</td>\n",
       "      <td>-1.088421</td>\n",
       "      <td>0.757187</td>\n",
       "      <td>1.860182</td>\n",
       "      <td>0.699759</td>\n",
       "      <td>-0.877712</td>\n",
       "      <td>-1.248901</td>\n",
       "      <td>-0.503236</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088074</td>\n",
       "      <td>0.587693</td>\n",
       "      <td>-0.510017</td>\n",
       "      <td>0.307161</td>\n",
       "      <td>0.546479</td>\n",
       "      <td>0.163082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.342252</td>\n",
       "      <td>-1.120577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>0.480383</td>\n",
       "      <td>0.758864</td>\n",
       "      <td>-0.641926</td>\n",
       "      <td>-1.088421</td>\n",
       "      <td>0.206982</td>\n",
       "      <td>-0.553269</td>\n",
       "      <td>-1.150289</td>\n",
       "      <td>-0.877712</td>\n",
       "      <td>0.285968</td>\n",
       "      <td>-0.503236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502419</td>\n",
       "      <td>0.587693</td>\n",
       "      <td>-0.510017</td>\n",
       "      <td>1.224350</td>\n",
       "      <td>0.546479</td>\n",
       "      <td>0.163082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.589815</td>\n",
       "      <td>0.741905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>0.418838</td>\n",
       "      <td>0.527969</td>\n",
       "      <td>-0.661469</td>\n",
       "      <td>-1.088421</td>\n",
       "      <td>0.601757</td>\n",
       "      <td>-0.477878</td>\n",
       "      <td>0.699759</td>\n",
       "      <td>-0.877712</td>\n",
       "      <td>1.162002</td>\n",
       "      <td>-0.503236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419081</td>\n",
       "      <td>-1.005386</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>1.224350</td>\n",
       "      <td>0.546479</td>\n",
       "      <td>0.163082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.599067</td>\n",
       "      <td>-0.711382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>1.160394</td>\n",
       "      <td>0.648443</td>\n",
       "      <td>-0.795425</td>\n",
       "      <td>-1.088421</td>\n",
       "      <td>0.601757</td>\n",
       "      <td>-0.789661</td>\n",
       "      <td>0.699759</td>\n",
       "      <td>1.183932</td>\n",
       "      <td>-1.248901</td>\n",
       "      <td>-0.503236</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088074</td>\n",
       "      <td>-1.005386</td>\n",
       "      <td>0.457049</td>\n",
       "      <td>1.224350</td>\n",
       "      <td>0.546479</td>\n",
       "      <td>0.163082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.587180</td>\n",
       "      <td>0.529380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.664618</td>\n",
       "      <td>0.635124</td>\n",
       "      <td>-0.667847</td>\n",
       "      <td>-1.088421</td>\n",
       "      <td>0.809438</td>\n",
       "      <td>0.759688</td>\n",
       "      <td>0.699759</td>\n",
       "      <td>1.871147</td>\n",
       "      <td>1.162002</td>\n",
       "      <td>-0.503236</td>\n",
       "      <td>...</td>\n",
       "      <td>1.088074</td>\n",
       "      <td>-1.005386</td>\n",
       "      <td>-0.510017</td>\n",
       "      <td>0.307161</td>\n",
       "      <td>0.546479</td>\n",
       "      <td>0.163082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.563687</td>\n",
       "      <td>-0.646952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.631327</td>\n",
       "      <td>0.599108</td>\n",
       "      <td>-0.864015</td>\n",
       "      <td>-1.088421</td>\n",
       "      <td>1.319790</td>\n",
       "      <td>0.573233</td>\n",
       "      <td>0.699759</td>\n",
       "      <td>1.871147</td>\n",
       "      <td>-1.248901</td>\n",
       "      <td>-0.503236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.502419</td>\n",
       "      <td>-1.005386</td>\n",
       "      <td>-0.747057</td>\n",
       "      <td>-0.610027</td>\n",
       "      <td>-1.252365</td>\n",
       "      <td>0.163082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.563687</td>\n",
       "      <td>-2.216728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows × 1119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.089124 -0.180325 -0.537766 -1.088421 -0.427138  1.036690  0.699759   \n",
       "1   -0.413332  0.515227 -0.882033 -1.088421 -1.061257  1.362584  0.699759   \n",
       "2   -1.475836 -1.990814 -0.993420 -1.088421  1.235876  1.670966  0.699759   \n",
       "3   -1.965243 -1.877247 -0.888654 -1.088421  0.362412  1.419465  0.699759   \n",
       "4   -0.798722 -0.617008 -0.926136 -1.088421  0.757187  1.860182  0.699759   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "381  0.480383  0.758864 -0.641926 -1.088421  0.206982 -0.553269 -1.150289   \n",
       "382  0.418838  0.527969 -0.661469 -1.088421  0.601757 -0.477878  0.699759   \n",
       "383  1.160394  0.648443 -0.795425 -1.088421  0.601757 -0.789661  0.699759   \n",
       "384  0.664618  0.635124 -0.667847 -1.088421  0.809438  0.759688  0.699759   \n",
       "385  0.631327  0.599108 -0.864015 -1.088421  1.319790  0.573233  0.699759   \n",
       "\n",
       "            7         8         9  ...       774       775       776  \\\n",
       "0   -0.877712  1.162002 -0.503236  ...  1.088074  0.587693  0.822062   \n",
       "1   -0.877712 -1.379220 -0.503236  ...  1.088074  0.587693  1.187075   \n",
       "2   -0.877712 -1.379220 -0.503236  ...  0.419081  0.587693  1.187075   \n",
       "3   -0.877712 -1.248901 -0.503236  ...  0.166574  0.587693 -0.145004   \n",
       "4   -0.877712 -1.248901 -0.503236  ...  1.088074  0.587693 -0.510017   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "381 -0.877712  0.285968 -0.503236  ... -0.502419  0.587693 -0.510017   \n",
       "382 -0.877712  1.162002 -0.503236  ...  0.419081 -1.005386  0.457049   \n",
       "383  1.183932 -1.248901 -0.503236  ...  1.088074 -1.005386  0.457049   \n",
       "384  1.871147  1.162002 -0.503236  ...  1.088074 -1.005386 -0.510017   \n",
       "385  1.871147 -1.248901 -0.503236  ... -0.502419 -1.005386 -0.747057   \n",
       "\n",
       "          777       778       779  780  781       782         y  \n",
       "0    0.307161  0.546479  0.163082  0.0  0.0 -1.345343 -0.432183  \n",
       "1    1.224350  0.546479  0.163082  0.0  0.0 -1.345343 -0.729170  \n",
       "2    1.224350  0.546479  0.163082  0.0  0.0 -1.345343 -1.331194  \n",
       "3    1.224350  0.546479  0.163082  0.0  0.0 -1.345343  0.373677  \n",
       "4    0.307161  0.546479  0.163082  0.0  0.0 -1.342252 -1.120577  \n",
       "..        ...       ...       ...  ...  ...       ...       ...  \n",
       "381  1.224350  0.546479  0.163082  0.0  0.0  1.589815  0.741905  \n",
       "382  1.224350  0.546479  0.163082  0.0  0.0  1.599067 -0.711382  \n",
       "383  1.224350  0.546479  0.163082  0.0  0.0  1.587180  0.529380  \n",
       "384  0.307161  0.546479  0.163082  0.0  0.0  1.563687 -0.646952  \n",
       "385 -0.610027 -1.252365  0.163082  0.0  0.0  1.563687 -2.216728  \n",
       "\n",
       "[386 rows x 1119 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_znorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightgbm\\basic.py:696: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\"Usage of np.ndarray subset (sliced data) is not recommended \"\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m regr4\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     83\u001b[0m predictions4a \u001b[38;5;241m=\u001b[39m recursive_multistep_forecasting(X_test, regr4, horizon)\n\u001b[1;32m---> 84\u001b[0m \u001b[43mregr5\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m predictions5a \u001b[38;5;241m=\u001b[39m recursive_multistep_forecasting(X_test, regr5, horizon)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# regr6.fit(X_train, y_train)\u001b[39;00m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# predictions6a = recursive_multistep_forecasting(X_test, regr6, horizon)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############## AUTO ##############\n",
    "\n",
    "horizon = 12\n",
    "window = 12\n",
    "\n",
    "\n",
    "products = sorted([name for name in os.listdir('./uf/') if os.path.isdir(os.path.join('./uf/', name))])\n",
    " \n",
    "for product in products:\n",
    "    folder_path = f'./uf/{product}/'\n",
    "    # Read the CSV files and extract estado names\n",
    "    estados = read_csv_files(folder_path)\n",
    "    \n",
    "    for estado in estados:\n",
    "\n",
    "\n",
    "        ########################################\n",
    "        products = sorted([name for name in os.listdir('./uf/') if os.path.isdir(os.path.join('./uf/', name))])\n",
    "\n",
    "        folder_path = f'./uf/{product}/'\n",
    "        # Read the CSV files and extract estado names\n",
    "        estados = read_csv_files(folder_path)\n",
    "\n",
    "        # Carregamento do arquivo csv com todas as features\n",
    "        df_c = pd.read_csv(f'./concatenate/{product}_{window}_{estado}_concatenated.csv')\n",
    "\n",
    "        df_c_ts = df_c.iloc[:, 0]\n",
    "        df_features = df_c.drop(df_c.columns[0], axis=1)\n",
    "\n",
    "        df_t = pd.read_csv(f'./uf/{product}/mensal_{estado}_{product}.csv', header=0, sep=\";\")\n",
    "\n",
    "        series = df_t['m3']\n",
    "        target = rolling_window(series, window)\n",
    "\n",
    "        # Exclude the first 24 rows and get the 'm3' column\n",
    "        target_norm = target.iloc[:, -1].tail(386).reset_index(drop=True)\n",
    "\n",
    "        # Normalization of features\n",
    "        df_c_znorm = df_features.apply(znorm, axis=0)\n",
    "        df_c_znorm.fillna(0, inplace=True)\n",
    "        df_c_znorm['y'] = target_norm\n",
    "\n",
    "        #### Possível seleção de Conjunto de Features em df_c_znorm (wind=12) ####\n",
    "\n",
    "        # timestamp = 1\n",
    "        # catch22 = 22 \n",
    "        # cesium = 117 \n",
    "        # tsfeatures = 42 \n",
    "        # tsfel = 140\n",
    "        # tsflex = 14 \n",
    "        # tsfresh = 783\n",
    "\n",
    "        ##################################################################################\n",
    "        # Divisão dos dados em treino/teste considerando o horizonte de predição de 12 meses\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_c_znorm, horizon)\n",
    "\n",
    "        #######################  lgb  #######################\n",
    "        num_round = 100\n",
    "\n",
    "        # Convert data to LightGBM dataset format\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "        ############## Regressores ##################\n",
    "        # regr1 = LinearRegression()\n",
    "        regr2 = KNeighborsRegressor(n_neighbors = 3)\n",
    "        regr3 = XGBRegressor()\n",
    "        regr4 = SVR(kernel='rbf')\n",
    "        regr5 = RandomForestRegressor()\n",
    "        # regr6 = MLPRegressor(random_state=1, activation='relu', max_iter=500)\n",
    "        regr7 = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression', metric='rmse', \n",
    "                                num_leaves=31, learning_rate=0.05, feature_fraction=0.9, \n",
    "                                bagging_fraction=0.8, bagging_freq=5, verbose=-1)\n",
    "\n",
    "        # Treinamento dos modelos\n",
    "        # regr1.fit(X_train, y_train)\n",
    "        # predictions1a = recursive_multistep_forecasting(X_test, regr1, horizon)\n",
    "        regr2.fit(X_train, y_train)\n",
    "        predictions2a = recursive_multistep_forecasting(X_test, regr2, horizon)\n",
    "        regr3.fit(X_train, y_train)\n",
    "        predictions3a = recursive_multistep_forecasting(X_test, regr3, horizon)\n",
    "        regr4.fit(X_train, y_train)\n",
    "        predictions4a = recursive_multistep_forecasting(X_test, regr4, horizon)\n",
    "        regr5.fit(X_train, y_train)\n",
    "        predictions5a = recursive_multistep_forecasting(X_test, regr5, horizon)\n",
    "        # regr6.fit(X_train, y_train)\n",
    "        # predictions6a = recursive_multistep_forecasting(X_test, regr6, horizon)\n",
    "        regr7.fit(X_train, y_train)\n",
    "        predictions7a = recursive_multistep_forecasting(X_test, regr7, horizon)\n",
    "\n",
    "        # Recupera a média e desvio-padrão da última subsequência observada\n",
    "        mean_norm, std_norm = get_stats_norm(series, horizon, window)\n",
    "\n",
    "        # Reescala a predição\n",
    "        # predictions1 = znorm_reverse(predictions1a, mean_norm, std_norm)\n",
    "        predictions2 = znorm_reverse(predictions2a, mean_norm, std_norm)\n",
    "        predictions3 = znorm_reverse(predictions3a, mean_norm, std_norm)\n",
    "        predictions4 = znorm_reverse(predictions4a, mean_norm, std_norm)\n",
    "        predictions5 = znorm_reverse(predictions5a, mean_norm, std_norm)\n",
    "        # predictions6 = znorm_reverse(predictions6a, mean_norm, std_norm)\n",
    "        predictions7 = znorm_reverse(predictions7a, mean_norm, std_norm)\n",
    "\n",
    "\n",
    "        ##########################\n",
    "\n",
    "        valores_reais = series.tail(12)\n",
    "        valores_reais.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # mape_result1 = mape(valores_reais, predictions1)\n",
    "        mape_result2 = mape(valores_reais, predictions2)\n",
    "        mape_result3 = mape(valores_reais, predictions3)\n",
    "        mape_result4 = mape(valores_reais, predictions4)\n",
    "        mape_result5 = mape(valores_reais, predictions5)\n",
    "        # mape_result6 = mape(valores_reais, predictions6)\n",
    "        mape_result7 = mape(valores_reais, predictions7)\n",
    "\n",
    "        # pbe_result1 = pbe(valores_reais, predictions1)\n",
    "        pbe_result2 = pbe(valores_reais, predictions2)\n",
    "        pbe_result3 = pbe(valores_reais, predictions3)\n",
    "        pbe_result4 = pbe(valores_reais, predictions4)\n",
    "        pbe_result5 = pbe(valores_reais, predictions5)\n",
    "        # pbe_result6 = pbe(valores_reais, predictions6)\n",
    "        pbe_result7 = pbe(valores_reais, predictions7)\n",
    "\n",
    "        # pocid_result1 = pocid(valores_reais, predictions1)\n",
    "        pocid_result2 = pocid(valores_reais, predictions2)\n",
    "        pocid_result3 = pocid(valores_reais, predictions3)\n",
    "        pocid_result4 = pocid(valores_reais, predictions4)\n",
    "        pocid_result5 = pocid(valores_reais, predictions5)\n",
    "        # pocid_result6 = pocid(valores_reais, predictions6)\n",
    "        pocid_result7 = pocid(valores_reais, predictions7)\n",
    "\n",
    "        # p1 = ', '.join(map(str, predictions1))\n",
    "        p2 = ', '.join(map(str, predictions2))\n",
    "        p3 = ', '.join(map(str, predictions3))\n",
    "        p4 = ', '.join(map(str, predictions4))\n",
    "        p5 = ', '.join(map(str, predictions5))\n",
    "        # p6 = ', '.join(map(str, predictions6))\n",
    "        p7 = ', '.join(map(str, predictions7))\n",
    "\n",
    "        \n",
    "       \n",
    "        rows_data = [\n",
    "            # [product,estado,'LR',fd1,mape_result1,pocid_result1,pbe_result1,p1],\n",
    "            [product,estado,'kNN',mape_result2,pocid_result2,pbe_result2,p2],\n",
    "            [product,estado,'XGB',mape_result3,pocid_result3,pbe_result3,p3],\n",
    "            [product,estado,'SVR',mape_result4,pocid_result4,pbe_result4,p4],\n",
    "            [product,estado,'RF',mape_result5,pocid_result5,pbe_result5,p5],\n",
    "            # [product,estado,'MLP',fd6,mape_result6,pocid_result6,pbe_result6,p6],\n",
    "            [product,estado,'LGB',mape_result7,pocid_result7,pbe_result7,p7]             \n",
    "        ]\n",
    "        \n",
    "        # CSV Output VALORES REAIS\n",
    "        with open(f'Metrics_ALL_{product}_{window}_output.csv', 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row_data in rows_data:\n",
    "                writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012472</td>\n",
       "      <td>0.688426</td>\n",
       "      <td>-1.086133</td>\n",
       "      <td>-1.363399</td>\n",
       "      <td>0.180405</td>\n",
       "      <td>-2.453987</td>\n",
       "      <td>0.724354</td>\n",
       "      <td>-0.882084</td>\n",
       "      <td>-1.119653</td>\n",
       "      <td>-0.478852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500146</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>0.199642</td>\n",
       "      <td>0.677234</td>\n",
       "      <td>0.55705</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.630105</td>\n",
       "      <td>-0.367040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.195584</td>\n",
       "      <td>-0.138288</td>\n",
       "      <td>-1.067174</td>\n",
       "      <td>-1.363399</td>\n",
       "      <td>0.180405</td>\n",
       "      <td>-2.578893</td>\n",
       "      <td>0.724354</td>\n",
       "      <td>-0.882084</td>\n",
       "      <td>-1.255009</td>\n",
       "      <td>-0.478852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731321</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>0.199642</td>\n",
       "      <td>0.677234</td>\n",
       "      <td>0.55705</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.512714</td>\n",
       "      <td>-0.448103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.238127</td>\n",
       "      <td>-0.094751</td>\n",
       "      <td>-1.062794</td>\n",
       "      <td>-1.363399</td>\n",
       "      <td>0.180405</td>\n",
       "      <td>-2.517937</td>\n",
       "      <td>0.724354</td>\n",
       "      <td>-0.882084</td>\n",
       "      <td>-1.390364</td>\n",
       "      <td>-0.478852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731321</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>0.199642</td>\n",
       "      <td>0.677234</td>\n",
       "      <td>0.55705</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.512714</td>\n",
       "      <td>-0.686648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.270423</td>\n",
       "      <td>-0.059946</td>\n",
       "      <td>-1.029231</td>\n",
       "      <td>-1.363399</td>\n",
       "      <td>0.180405</td>\n",
       "      <td>-2.464947</td>\n",
       "      <td>0.724354</td>\n",
       "      <td>-0.882084</td>\n",
       "      <td>0.203826</td>\n",
       "      <td>-0.478852</td>\n",
       "      <td>...</td>\n",
       "      <td>1.343796</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>0.448847</td>\n",
       "      <td>0.677234</td>\n",
       "      <td>0.55705</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.512714</td>\n",
       "      <td>0.194564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.268484</td>\n",
       "      <td>-0.061738</td>\n",
       "      <td>-1.029977</td>\n",
       "      <td>-1.363399</td>\n",
       "      <td>0.180405</td>\n",
       "      <td>-2.337566</td>\n",
       "      <td>0.724354</td>\n",
       "      <td>-0.882084</td>\n",
       "      <td>0.203826</td>\n",
       "      <td>-0.478852</td>\n",
       "      <td>...</td>\n",
       "      <td>1.956270</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>1.358293</td>\n",
       "      <td>0.677234</td>\n",
       "      <td>0.55705</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.514044</td>\n",
       "      <td>-0.759379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1.147756</td>\n",
       "      <td>1.215125</td>\n",
       "      <td>-0.943763</td>\n",
       "      <td>-0.901352</td>\n",
       "      <td>0.791160</td>\n",
       "      <td>0.840615</td>\n",
       "      <td>-0.355185</td>\n",
       "      <td>-0.234775</td>\n",
       "      <td>-0.305713</td>\n",
       "      <td>2.088327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731321</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>0.859885</td>\n",
       "      <td>0.677234</td>\n",
       "      <td>0.55705</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134764</td>\n",
       "      <td>-0.100169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>2.068185</td>\n",
       "      <td>1.149135</td>\n",
       "      <td>-0.999104</td>\n",
       "      <td>-0.901352</td>\n",
       "      <td>1.698456</td>\n",
       "      <td>0.768589</td>\n",
       "      <td>-0.355185</td>\n",
       "      <td>-0.234775</td>\n",
       "      <td>0.349409</td>\n",
       "      <td>-0.478852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.118846</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>1.109089</td>\n",
       "      <td>0.677234</td>\n",
       "      <td>0.55705</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.140239</td>\n",
       "      <td>1.331016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>2.245612</td>\n",
       "      <td>0.823267</td>\n",
       "      <td>-0.962540</td>\n",
       "      <td>-0.901352</td>\n",
       "      <td>0.648576</td>\n",
       "      <td>0.614760</td>\n",
       "      <td>-0.355185</td>\n",
       "      <td>-0.234775</td>\n",
       "      <td>-0.960835</td>\n",
       "      <td>-0.478852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112328</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>1.109089</td>\n",
       "      <td>0.677234</td>\n",
       "      <td>0.55705</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203675</td>\n",
       "      <td>2.118656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.789120</td>\n",
       "      <td>0.468766</td>\n",
       "      <td>-0.678595</td>\n",
       "      <td>-0.901352</td>\n",
       "      <td>0.315476</td>\n",
       "      <td>0.711802</td>\n",
       "      <td>-0.355185</td>\n",
       "      <td>-0.234775</td>\n",
       "      <td>-0.960835</td>\n",
       "      <td>-0.478852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.731321</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>0.199642</td>\n",
       "      <td>0.061740</td>\n",
       "      <td>0.55705</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283670</td>\n",
       "      <td>1.799413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.425657</td>\n",
       "      <td>0.146158</td>\n",
       "      <td>-0.138684</td>\n",
       "      <td>-0.439304</td>\n",
       "      <td>0.535038</td>\n",
       "      <td>0.497017</td>\n",
       "      <td>-0.355185</td>\n",
       "      <td>-1.529392</td>\n",
       "      <td>-0.402768</td>\n",
       "      <td>-0.478852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112328</td>\n",
       "      <td>0.727971</td>\n",
       "      <td>0.199642</td>\n",
       "      <td>0.061740</td>\n",
       "      <td>0.55705</td>\n",
       "      <td>0.323171</td>\n",
       "      <td>0.2195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.390212</td>\n",
       "      <td>1.532778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows × 1119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.012472  0.688426 -1.086133 -1.363399  0.180405 -2.453987  0.724354   \n",
       "1    0.195584 -0.138288 -1.067174 -1.363399  0.180405 -2.578893  0.724354   \n",
       "2    0.238127 -0.094751 -1.062794 -1.363399  0.180405 -2.517937  0.724354   \n",
       "3    0.270423 -0.059946 -1.029231 -1.363399  0.180405 -2.464947  0.724354   \n",
       "4    0.268484 -0.061738 -1.029977 -1.363399  0.180405 -2.337566  0.724354   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "381  1.147756  1.215125 -0.943763 -0.901352  0.791160  0.840615 -0.355185   \n",
       "382  2.068185  1.149135 -0.999104 -0.901352  1.698456  0.768589 -0.355185   \n",
       "383  2.245612  0.823267 -0.962540 -0.901352  0.648576  0.614760 -0.355185   \n",
       "384  0.789120  0.468766 -0.678595 -0.901352  0.315476  0.711802 -0.355185   \n",
       "385  0.425657  0.146158 -0.138684 -0.439304  0.535038  0.497017 -0.355185   \n",
       "\n",
       "            7         8         9  ...       774       775       776  \\\n",
       "0   -0.882084 -1.119653 -0.478852  ...  0.500146  0.727971  0.199642   \n",
       "1   -0.882084 -1.255009 -0.478852  ...  0.731321  0.727971  0.199642   \n",
       "2   -0.882084 -1.390364 -0.478852  ...  0.731321  0.727971  0.199642   \n",
       "3   -0.882084  0.203826 -0.478852  ...  1.343796  0.727971  0.448847   \n",
       "4   -0.882084  0.203826 -0.478852  ...  1.956270  0.727971  1.358293   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "381 -0.234775 -0.305713  2.088327  ...  0.731321  0.727971  0.859885   \n",
       "382 -0.234775  0.349409 -0.478852  ...  0.118846  0.727971  1.109089   \n",
       "383 -0.234775 -0.960835 -0.478852  ... -0.112328  0.727971  1.109089   \n",
       "384 -0.234775 -0.960835 -0.478852  ...  0.731321  0.727971  0.199642   \n",
       "385 -1.529392 -0.402768 -0.478852  ... -0.112328  0.727971  0.199642   \n",
       "\n",
       "          777      778       779     780  781       782         y  \n",
       "0    0.677234  0.55705  0.323171  0.2195  0.0  1.630105 -0.367040  \n",
       "1    0.677234  0.55705  0.323171  0.2195  0.0  1.512714 -0.448103  \n",
       "2    0.677234  0.55705  0.323171  0.2195  0.0  1.512714 -0.686648  \n",
       "3    0.677234  0.55705  0.323171  0.2195  0.0  1.512714  0.194564  \n",
       "4    0.677234  0.55705  0.323171  0.2195  0.0  1.514044 -0.759379  \n",
       "..        ...      ...       ...     ...  ...       ...       ...  \n",
       "381  0.677234  0.55705  0.323171  0.2195  0.0  0.134764 -0.100169  \n",
       "382  0.677234  0.55705  0.323171  0.2195  0.0  0.140239  1.331016  \n",
       "383  0.677234  0.55705  0.323171  0.2195  0.0  0.203675  2.118656  \n",
       "384  0.061740  0.55705  0.323171  0.2195  0.0  0.283670  1.799413  \n",
       "385  0.061740  0.55705  0.323171  0.2195  0.0  0.390212  1.532778  \n",
       "\n",
       "[386 rows x 1119 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_znorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>773</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199201</td>\n",
       "      <td>-0.207302</td>\n",
       "      <td>0.174793</td>\n",
       "      <td>0.606041</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-2.300518</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>...</td>\n",
       "      <td>1.277034</td>\n",
       "      <td>1.475076</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.504788</td>\n",
       "      <td>2.043192</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9136.859000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>199202</td>\n",
       "      <td>-0.105213</td>\n",
       "      <td>-0.303797</td>\n",
       "      <td>0.618322</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-2.417237</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.022039</td>\n",
       "      <td>...</td>\n",
       "      <td>1.078992</td>\n",
       "      <td>1.549826</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.504788</td>\n",
       "      <td>2.043192</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8857.642429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>199203</td>\n",
       "      <td>-0.081495</td>\n",
       "      <td>-0.278593</td>\n",
       "      <td>0.621159</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-2.360276</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>...</td>\n",
       "      <td>1.277034</td>\n",
       "      <td>1.549826</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.504788</td>\n",
       "      <td>2.043192</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8857.642429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>199204</td>\n",
       "      <td>-0.063490</td>\n",
       "      <td>-0.258444</td>\n",
       "      <td>0.642899</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-2.310760</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1.277034</td>\n",
       "      <td>1.747868</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.557113</td>\n",
       "      <td>2.043192</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8857.642429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>199205</td>\n",
       "      <td>-0.064570</td>\n",
       "      <td>-0.259481</td>\n",
       "      <td>0.642416</td>\n",
       "      <td>1</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>-2.191727</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>...</td>\n",
       "      <td>1.549826</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.748067</td>\n",
       "      <td>2.043192</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8860.805286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>202310</td>\n",
       "      <td>0.425640</td>\n",
       "      <td>0.479703</td>\n",
       "      <td>0.698260</td>\n",
       "      <td>2</td>\n",
       "      <td>0.838699</td>\n",
       "      <td>0.778143</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.277034</td>\n",
       "      <td>1.549826</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.643418</td>\n",
       "      <td>2.043192</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5580.162571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>202311</td>\n",
       "      <td>0.938797</td>\n",
       "      <td>0.441500</td>\n",
       "      <td>0.662414</td>\n",
       "      <td>2</td>\n",
       "      <td>1.054920</td>\n",
       "      <td>0.710838</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>1.351784</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.695743</td>\n",
       "      <td>2.043192</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5593.184143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>202312</td>\n",
       "      <td>1.037716</td>\n",
       "      <td>0.252853</td>\n",
       "      <td>0.686097</td>\n",
       "      <td>2</td>\n",
       "      <td>0.804719</td>\n",
       "      <td>0.567091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>1.277034</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.695743</td>\n",
       "      <td>2.043192</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5744.069571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>202401</td>\n",
       "      <td>0.225694</td>\n",
       "      <td>0.047631</td>\n",
       "      <td>0.870018</td>\n",
       "      <td>2</td>\n",
       "      <td>0.725336</td>\n",
       "      <td>0.657773</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.549826</td>\n",
       "      <td>1.549826</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.504788</td>\n",
       "      <td>1.889159</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5934.338571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>202402</td>\n",
       "      <td>0.023057</td>\n",
       "      <td>-0.139129</td>\n",
       "      <td>1.219738</td>\n",
       "      <td>3</td>\n",
       "      <td>0.777661</td>\n",
       "      <td>0.457066</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>...</td>\n",
       "      <td>1.277034</td>\n",
       "      <td>1.277034</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.504788</td>\n",
       "      <td>1.889159</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.94591</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6187.751000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows × 1119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     timestamp         0         1         2  3         4         5         6  \\\n",
       "0       199201 -0.207302  0.174793  0.606041  1  0.693147 -2.300518  1.000000   \n",
       "1       199202 -0.105213 -0.303797  0.618322  1  0.693147 -2.417237  1.000000   \n",
       "2       199203 -0.081495 -0.278593  0.621159  1  0.693147 -2.360276  1.000000   \n",
       "3       199204 -0.063490 -0.258444  0.642899  1  0.693147 -2.310760  1.000000   \n",
       "4       199205 -0.064570 -0.259481  0.642416  1  0.693147 -2.191727  1.000000   \n",
       "..         ...       ...       ...       ... ..       ...       ...       ...   \n",
       "381     202310  0.425640  0.479703  0.698260  2  0.838699  0.778143  0.909091   \n",
       "382     202311  0.938797  0.441500  0.662414  2  1.054920  0.710838  0.909091   \n",
       "383     202312  1.037716  0.252853  0.686097  2  0.804719  0.567091  0.909091   \n",
       "384     202401  0.225694  0.047631  0.870018  2  0.725336  0.657773  0.909091   \n",
       "385     202402  0.023057 -0.139129  1.219738  3  0.777661  0.457066  0.909091   \n",
       "\n",
       "       7         8  ...       773       774      775       776       777  \\\n",
       "0    3.0  0.030303  ...  1.277034  1.475076  1.94591  1.504788  2.043192   \n",
       "1    3.0  0.022039  ...  1.078992  1.549826  1.94591  1.504788  2.043192   \n",
       "2    3.0  0.013774  ...  1.277034  1.549826  1.94591  1.504788  2.043192   \n",
       "3    3.0  0.111111  ...  1.277034  1.747868  1.94591  1.557113  2.043192   \n",
       "4    3.0  0.111111  ...  1.549826  1.945910  1.94591  1.748067  2.043192   \n",
       "..   ...       ...  ...       ...       ...      ...       ...       ...   \n",
       "381  4.0  0.080000  ...  1.277034  1.549826  1.94591  1.643418  2.043192   \n",
       "382  4.0  0.120000  ...  0.955700  1.351784  1.94591  1.695743  2.043192   \n",
       "383  4.0  0.040000  ...  0.955700  1.277034  1.94591  1.695743  2.043192   \n",
       "384  4.0  0.040000  ...  1.549826  1.549826  1.94591  1.504788  1.889159   \n",
       "385  2.0  0.074074  ...  1.277034  1.277034  1.94591  1.504788  1.889159   \n",
       "\n",
       "          778      779       780  781          782  \n",
       "0    2.079442  1.94591  1.791759  0.0  9136.859000  \n",
       "1    2.079442  1.94591  1.791759  0.0  8857.642429  \n",
       "2    2.079442  1.94591  1.791759  0.0  8857.642429  \n",
       "3    2.079442  1.94591  1.791759  0.0  8857.642429  \n",
       "4    2.079442  1.94591  1.791759  0.0  8860.805286  \n",
       "..        ...      ...       ...  ...          ...  \n",
       "381  2.079442  1.94591  1.791759  0.0  5580.162571  \n",
       "382  2.079442  1.94591  1.791759  0.0  5593.184143  \n",
       "383  2.079442  1.94591  1.791759  0.0  5744.069571  \n",
       "384  2.079442  1.94591  1.791759  0.0  5934.338571  \n",
       "385  2.079442  1.94591  1.791759  0.0  6187.751000  \n",
       "\n",
       "[386 rows x 1119 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      199201\n",
       "1      199202\n",
       "2      199203\n",
       "3      199204\n",
       "4      199205\n",
       "        ...  \n",
       "381    202310\n",
       "382    202311\n",
       "383    202312\n",
       "384    202401\n",
       "385    202402\n",
       "Name: timestamp, Length: 386, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.246839</td>\n",
       "      <td>-0.589506</td>\n",
       "      <td>0.048393</td>\n",
       "      <td>0.549425</td>\n",
       "      <td>-1.281594</td>\n",
       "      <td>-0.820101</td>\n",
       "      <td>0.467134</td>\n",
       "      <td>-0.611513</td>\n",
       "      <td>-0.225369</td>\n",
       "      <td>-0.445823</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033322</td>\n",
       "      <td>0.585361</td>\n",
       "      <td>-0.197712</td>\n",
       "      <td>1.061748</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.364229</td>\n",
       "      <td>2455.831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.339209</td>\n",
       "      <td>-0.019474</td>\n",
       "      <td>-0.129771</td>\n",
       "      <td>1.096018</td>\n",
       "      <td>-2.403133</td>\n",
       "      <td>-0.783326</td>\n",
       "      <td>0.467134</td>\n",
       "      <td>-0.611513</td>\n",
       "      <td>-0.225369</td>\n",
       "      <td>-0.445823</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033322</td>\n",
       "      <td>-1.135965</td>\n",
       "      <td>0.089040</td>\n",
       "      <td>1.061748</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.362098</td>\n",
       "      <td>2110.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.093684</td>\n",
       "      <td>-1.051946</td>\n",
       "      <td>-0.382254</td>\n",
       "      <td>-0.543761</td>\n",
       "      <td>-0.160056</td>\n",
       "      <td>-0.983032</td>\n",
       "      <td>0.467134</td>\n",
       "      <td>-0.611513</td>\n",
       "      <td>-0.755352</td>\n",
       "      <td>-0.445823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319119</td>\n",
       "      <td>-1.135965</td>\n",
       "      <td>1.135513</td>\n",
       "      <td>1.061748</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.362098</td>\n",
       "      <td>2245.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.850453</td>\n",
       "      <td>-1.124251</td>\n",
       "      <td>-0.400006</td>\n",
       "      <td>0.549425</td>\n",
       "      <td>-0.716361</td>\n",
       "      <td>-1.094968</td>\n",
       "      <td>0.467134</td>\n",
       "      <td>-0.611513</td>\n",
       "      <td>-0.225369</td>\n",
       "      <td>2.243045</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033322</td>\n",
       "      <td>0.585361</td>\n",
       "      <td>0.848761</td>\n",
       "      <td>1.061748</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.362098</td>\n",
       "      <td>2448.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.964566</td>\n",
       "      <td>-0.626619</td>\n",
       "      <td>-0.320923</td>\n",
       "      <td>-0.543761</td>\n",
       "      <td>-0.590377</td>\n",
       "      <td>-1.246471</td>\n",
       "      <td>0.467134</td>\n",
       "      <td>-0.611513</td>\n",
       "      <td>1.214804</td>\n",
       "      <td>-0.445823</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033322</td>\n",
       "      <td>0.585361</td>\n",
       "      <td>0.848761</td>\n",
       "      <td>1.061748</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.360171</td>\n",
       "      <td>2261.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>-1.519490</td>\n",
       "      <td>-1.735806</td>\n",
       "      <td>-0.885453</td>\n",
       "      <td>-1.090354</td>\n",
       "      <td>0.531161</td>\n",
       "      <td>0.558451</td>\n",
       "      <td>0.467134</td>\n",
       "      <td>0.205248</td>\n",
       "      <td>-1.163266</td>\n",
       "      <td>-0.445823</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033322</td>\n",
       "      <td>0.585361</td>\n",
       "      <td>0.848761</td>\n",
       "      <td>1.061748</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.767920</td>\n",
       "      <td>35301.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>-1.527852</td>\n",
       "      <td>-1.743738</td>\n",
       "      <td>-0.897765</td>\n",
       "      <td>-1.090354</td>\n",
       "      <td>0.009370</td>\n",
       "      <td>0.614196</td>\n",
       "      <td>-1.581887</td>\n",
       "      <td>1.022010</td>\n",
       "      <td>-1.291810</td>\n",
       "      <td>-0.445823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319119</td>\n",
       "      <td>-1.135965</td>\n",
       "      <td>1.135513</td>\n",
       "      <td>1.061748</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.769398</td>\n",
       "      <td>34727.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>-0.450490</td>\n",
       "      <td>-0.151739</td>\n",
       "      <td>-0.722950</td>\n",
       "      <td>-1.090354</td>\n",
       "      <td>-0.420951</td>\n",
       "      <td>-1.341866</td>\n",
       "      <td>-1.581887</td>\n",
       "      <td>1.022010</td>\n",
       "      <td>-1.291810</td>\n",
       "      <td>-0.445823</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033322</td>\n",
       "      <td>0.585361</td>\n",
       "      <td>0.848761</td>\n",
       "      <td>0.152499</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.769398</td>\n",
       "      <td>39848.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0.728141</td>\n",
       "      <td>0.202450</td>\n",
       "      <td>-0.524836</td>\n",
       "      <td>-1.090354</td>\n",
       "      <td>0.270266</td>\n",
       "      <td>1.770406</td>\n",
       "      <td>-1.581887</td>\n",
       "      <td>1.022010</td>\n",
       "      <td>0.350700</td>\n",
       "      <td>-0.445823</td>\n",
       "      <td>...</td>\n",
       "      <td>1.033322</td>\n",
       "      <td>0.585361</td>\n",
       "      <td>-0.197712</td>\n",
       "      <td>0.152499</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.764698</td>\n",
       "      <td>35655.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>0.530604</td>\n",
       "      <td>0.140876</td>\n",
       "      <td>-0.747461</td>\n",
       "      <td>-1.090354</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>1.773770</td>\n",
       "      <td>-1.581887</td>\n",
       "      <td>1.022010</td>\n",
       "      <td>-0.906177</td>\n",
       "      <td>-0.445823</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319119</td>\n",
       "      <td>-1.135965</td>\n",
       "      <td>-1.244185</td>\n",
       "      <td>-0.756750</td>\n",
       "      <td>0.410004</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.102329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.769287</td>\n",
       "      <td>30847.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows × 1119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0   -0.246839 -0.589506  0.048393  0.549425 -1.281594 -0.820101  0.467134   \n",
       "1   -0.339209 -0.019474 -0.129771  1.096018 -2.403133 -0.783326  0.467134   \n",
       "2   -1.093684 -1.051946 -0.382254 -0.543761 -0.160056 -0.983032  0.467134   \n",
       "3   -0.850453 -1.124251 -0.400006  0.549425 -0.716361 -1.094968  0.467134   \n",
       "4   -0.964566 -0.626619 -0.320923 -0.543761 -0.590377 -1.246471  0.467134   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "381 -1.519490 -1.735806 -0.885453 -1.090354  0.531161  0.558451  0.467134   \n",
       "382 -1.527852 -1.743738 -0.897765 -1.090354  0.009370  0.614196 -1.581887   \n",
       "383 -0.450490 -0.151739 -0.722950 -1.090354 -0.420951 -1.341866 -1.581887   \n",
       "384  0.728141  0.202450 -0.524836 -1.090354  0.270266  1.770406 -1.581887   \n",
       "385  0.530604  0.140876 -0.747461 -1.090354  0.100840  1.773770 -1.581887   \n",
       "\n",
       "            7         8         9  ...       774       775       776  \\\n",
       "0   -0.611513 -0.225369 -0.445823  ...  1.033322  0.585361 -0.197712   \n",
       "1   -0.611513 -0.225369 -0.445823  ...  1.033322 -1.135965  0.089040   \n",
       "2   -0.611513 -0.755352 -0.445823  ...  0.319119 -1.135965  1.135513   \n",
       "3   -0.611513 -0.225369  2.243045  ...  1.033322  0.585361  0.848761   \n",
       "4   -0.611513  1.214804 -0.445823  ...  1.033322  0.585361  0.848761   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "381  0.205248 -1.163266 -0.445823  ...  1.033322  0.585361  0.848761   \n",
       "382  1.022010 -1.291810 -0.445823  ...  0.319119 -1.135965  1.135513   \n",
       "383  1.022010 -1.291810 -0.445823  ...  1.033322  0.585361  0.848761   \n",
       "384  1.022010  0.350700 -0.445823  ...  1.033322  0.585361 -0.197712   \n",
       "385  1.022010 -0.906177 -0.445823  ...  0.319119 -1.135965 -1.244185   \n",
       "\n",
       "          777       778       779       780  781       782          y  \n",
       "0    1.061748  0.410004  0.153707  0.102329  0.0 -1.364229   2455.831  \n",
       "1    1.061748  0.410004  0.153707  0.102329  0.0 -1.362098   2110.210  \n",
       "2    1.061748  0.410004  0.153707  0.102329  0.0 -1.362098   2245.507  \n",
       "3    1.061748  0.410004  0.153707  0.102329  0.0 -1.362098   2448.490  \n",
       "4    1.061748  0.410004  0.153707  0.102329  0.0 -1.360171   2261.490  \n",
       "..        ...       ...       ...       ...  ...       ...        ...  \n",
       "381  1.061748  0.410004  0.153707  0.102329  0.0  1.767920  35301.000  \n",
       "382  1.061748  0.410004  0.153707  0.102329  0.0  1.769398  34727.055  \n",
       "383  0.152499  0.410004  0.153707  0.102329  0.0  1.769398  39848.000  \n",
       "384  0.152499  0.410004  0.153707  0.102329  0.0  1.764698  35655.300  \n",
       "385 -0.756750  0.410004  0.153707  0.102329  0.0  1.769287  30847.000  \n",
       "\n",
       "[386 rows x 1119 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_znorm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
