{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "############ LOADING ###############\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import pycatch22\n",
    "\n",
    "# Regressors\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost.sklearn import XGBRegressor \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "from warnings import simplefilter\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# variavel que evita NaN nos resultados\n",
    "epslon = 0.00005\n",
    "\n",
    "def pbe(y_true, y_pred):\n",
    "  if np.sum(y_true)!=0:\n",
    "    return 100*(np.sum(y_pred - y_true)/np.sum(y_true))\n",
    "  else:\n",
    "   return 100*(np.sum(y_pred - y_true)/(np.sum(y_true)+ epslon))  \n",
    "\n",
    "def pocid(y_true, y_pred):\n",
    "    n = len(y_true)\n",
    "    D = [1 if (y_pred[i] - y_pred[i-1]) * (y_true[i] - y_true[i-1]) > 0 else 0 for i in range(1, n)]\n",
    "    POCID = 100 * np.sum(D) / n\n",
    "    return POCID\n",
    "\n",
    "#função para normalização\n",
    "def znorm(x):\n",
    "  if np.std(x)!=0:\n",
    "    x_znorm = (x - np.mean(x)) / np.std(x)\n",
    "  else:\n",
    "    x_znorm = (x - np.mean(x)) / (np.std(x) + epslon) \n",
    "   \n",
    "  return x_znorm\n",
    "\n",
    "#função para desnormatização\n",
    "def znorm_reverse(x, mean_x, std_x):\n",
    "  x_denormalized = (np.array(x) * std_x) + mean_x\n",
    "  return x_denormalized\n",
    "\n",
    "def get_stats_norm(series, horizon, window):\n",
    "  last_subsequence = series[-(horizon+window):-horizon].values\n",
    "  last_mean = np.mean(last_subsequence)\n",
    "  last_std = np.std(last_subsequence)\n",
    "  return last_mean, last_std\n",
    "\n",
    "# Em geral, considera-se um tamanho de janela capaz de capturar um ciclo dos dados\n",
    "# Por exemplo, 12 observações no caso dos dados com frequência mensal\n",
    "def rolling_window(series, window):\n",
    "  data = []\n",
    "  for i in range(len(series)-window):\n",
    "    example = znorm(np.array(series[i:i+window+1]))\n",
    "    data.append(example)\n",
    "  df = pd.DataFrame(data)\n",
    "  return df\n",
    "\n",
    "# Para predição de vendas por UF (mensal), será considerado horizon = 12\n",
    "# Para predição de vendas por município (anual), será considerado horizon = 1\n",
    "def train_test_split(data, horizon):\n",
    "  X = data.iloc[:,:-1] # features\n",
    "  y = data.iloc[:,-1] # target\n",
    "\n",
    "  X_train = X[:-horizon] # features train\n",
    "  X_test =  X[-horizon:] # features test\n",
    "\n",
    "  y_train = y[:-horizon] # target train\n",
    "  y_test = y[-horizon:] # target test\n",
    "  return X_train, X_test, y_train, y_test\n",
    "\n",
    "def recursive_multistep_forecasting(X_test, model, horizon):\n",
    "  # example é composto pelas últimas observações vistas\n",
    "  # na prática, é o pbeprimeiro exemplo do conjunto de teste\n",
    "  example = X_test.iloc[0].values.reshape(1,-1)\n",
    "\n",
    "  preds = []\n",
    "  for i in range(horizon):\n",
    "    pred = model.predict(example)[0]\n",
    "    preds.append(pred)\n",
    "\n",
    "    # Descartar o valor da primeira posição do vetor de características\n",
    "    example = example[:,1:]\n",
    "\n",
    "    # Adicionar o valor predito na última posição do vetor de características\n",
    "    example = np.append(example, pred)\n",
    "    example = example.reshape(1,-1)\n",
    "  return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "#VERIFICAÇÃO DOS ESTADOS \n",
    "\n",
    "def extract_estado(file_name):\n",
    "    # Split the file name by underscores\n",
    "    parts = file_name.split('_')\n",
    "    # Extract the name between underscores\n",
    "    estado = parts[1]\n",
    "    return estado\n",
    "\n",
    "def read_csv_files(folder_path):\n",
    "    estados = []\n",
    "    # List all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "    # Iterate through each file\n",
    "    for file_name in files:\n",
    "        # Check if it's a CSV file\n",
    "        if file_name.endswith('.csv'):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            # Open the CSV file and read the data\n",
    "            with open(file_path, 'r', newline='') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                # Assuming the first row contains headers\n",
    "                headers = next(reader)\n",
    "                # Extract estado from file name and append to estados list\n",
    "                estado = extract_estado(file_name)\n",
    "                estados.append(estado)\n",
    "                estados.sort()\n",
    "    return estados\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but SVR was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\lightgbm\\basic.py:696: UserWarning: Usage of np.ndarray subset (sliced data) is not recommended due to it will double the peak memory cost in LightGBM.\n",
      "  _log_warning(\"Usage of np.ndarray subset (sliced data) is not recommended \"\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n",
      "C:\\Users\\jonas\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m regr2\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     79\u001b[0m predictions2a \u001b[38;5;241m=\u001b[39m recursive_multistep_forecasting(X_test, regr2, horizon)\n\u001b[1;32m---> 80\u001b[0m \u001b[43mregr3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m predictions3a \u001b[38;5;241m=\u001b[39m recursive_multistep_forecasting(X_test, regr3, horizon)\n\u001b[0;32m     82\u001b[0m regr4\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\sklearn.py:1090\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1079\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1081\u001b[0m (\n\u001b[0;32m   1082\u001b[0m     model,\n\u001b[0;32m   1083\u001b[0m     metric,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1088\u001b[0m     xgb_model, eval_metric, params, early_stopping_rounds, callbacks\n\u001b[0;32m   1089\u001b[0m )\n\u001b[1;32m-> 1090\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1091\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1092\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1093\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1094\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1095\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1096\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1097\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1098\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1099\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1101\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1102\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1105\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "############## Regressors All Features AUTO ##############\n",
    "\n",
    "horizon = 12\n",
    "window = 12\n",
    "\n",
    "\n",
    "products = sorted([name for name in os.listdir('./uf/') if os.path.isdir(os.path.join('./uf/', name))])\n",
    " \n",
    "for product in products:\n",
    "    folder_path = f'./uf/{product}/'\n",
    "    # Read the CSV files and extract estado names\n",
    "    estados = read_csv_files(folder_path)\n",
    "    \n",
    "    for estado in estados:\n",
    "\n",
    "\n",
    "        ########################################\n",
    "        products = sorted([name for name in os.listdir('./uf/') if os.path.isdir(os.path.join('./uf/', name))])\n",
    "\n",
    "        folder_path = f'./uf/{product}/'\n",
    "        # Read the CSV files and extract estado names\n",
    "        estados = read_csv_files(folder_path)\n",
    "\n",
    "        # Carregamento do arquivo csv com todas as features\n",
    "        df_c = pd.read_csv(f'./concatenate/{product}_{window}_{estado}_concatenated.csv')\n",
    "\n",
    "        df_c_ts = df_c.iloc[:, 0]\n",
    "        df_features = df_c.drop(df_c.columns[0], axis=1)\n",
    "\n",
    "        df_t = pd.read_csv(f'./uf/{product}/mensal_{estado}_{product}.csv', header=0, sep=\";\")\n",
    "\n",
    "        series = df_t['m3']\n",
    "        target = rolling_window(series, window)\n",
    "\n",
    "        # Exclude the first 24 rows and get the 'm3' column\n",
    "        target_norm = target.iloc[:, -1].tail(386).reset_index(drop=True)\n",
    "\n",
    "        # Normalization of features\n",
    "        df_c_znorm = df_features.apply(znorm, axis=0)\n",
    "        df_c_znorm.fillna(0, inplace=True)\n",
    "        df_c_znorm['y'] = target_norm\n",
    "\n",
    "        #### Possível seleção de Conjunto de Features em df_c_znorm (wind=12) ####\n",
    "\n",
    "        # timestamp = 1\n",
    "        # catch22 = 22 \n",
    "        # cesium = 117 \n",
    "        # tsfeatures = 42 \n",
    "        # tsfel = 140\n",
    "        # tsflex = 14 \n",
    "        # tsfresh = 783\n",
    "\n",
    "        ##################################################################################\n",
    "        # Divisão dos dados em treino/teste considerando o horizonte de predição de 12 meses\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df_c_znorm, horizon)\n",
    "\n",
    "        #######################  lgb  #######################\n",
    "        num_round = 100\n",
    "\n",
    "        # Convert data to LightGBM dataset format\n",
    "        train_data = lgb.Dataset(X_train, label=y_train)\n",
    "        test_data = lgb.Dataset(X_test, label=y_test)\n",
    "\n",
    "        ############## Regressores ##################\n",
    "        # regr1 = LinearRegression()\n",
    "        regr2 = KNeighborsRegressor(n_neighbors = 3)\n",
    "        regr3 = XGBRegressor()\n",
    "        regr4 = SVR(kernel='rbf')\n",
    "        regr5 = RandomForestRegressor()\n",
    "        # regr6 = MLPRegressor(random_state=1, activation='relu', max_iter=500)\n",
    "        regr7 = lgb.LGBMRegressor(boosting_type='gbdt', objective='regression', metric='rmse', \n",
    "                                num_leaves=31, learning_rate=0.05, feature_fraction=0.9, \n",
    "                                bagging_fraction=0.8, bagging_freq=5, verbose=-1)\n",
    "\n",
    "        # Treinamento dos modelos\n",
    "        # regr1.fit(X_train, y_train)\n",
    "        # predictions1a = recursive_multistep_forecasting(X_test, regr1, horizon)\n",
    "        regr2.fit(X_train, y_train)\n",
    "        predictions2a = recursive_multistep_forecasting(X_test, regr2, horizon)\n",
    "        regr3.fit(X_train, y_train)\n",
    "        predictions3a = recursive_multistep_forecasting(X_test, regr3, horizon)\n",
    "        regr4.fit(X_train, y_train)\n",
    "        predictions4a = recursive_multistep_forecasting(X_test, regr4, horizon)\n",
    "        regr5.fit(X_train, y_train)\n",
    "        predictions5a = recursive_multistep_forecasting(X_test, regr5, horizon)\n",
    "        # regr6.fit(X_train, y_train)\n",
    "        # predictions6a = recursive_multistep_forecasting(X_test, regr6, horizon)\n",
    "        regr7.fit(X_train, y_train)\n",
    "        predictions7a = recursive_multistep_forecasting(X_test, regr7, horizon)\n",
    "\n",
    "        # Recupera a média e desvio-padrão da última subsequência observada\n",
    "        mean_norm, std_norm = get_stats_norm(series, horizon, window)\n",
    "\n",
    "        # Reescala a predição\n",
    "        # predictions1 = znorm_reverse(predictions1a, mean_norm, std_norm)\n",
    "        predictions2 = znorm_reverse(predictions2a, mean_norm, std_norm)\n",
    "        predictions3 = znorm_reverse(predictions3a, mean_norm, std_norm)\n",
    "        predictions4 = znorm_reverse(predictions4a, mean_norm, std_norm)\n",
    "        predictions5 = znorm_reverse(predictions5a, mean_norm, std_norm)\n",
    "        # predictions6 = znorm_reverse(predictions6a, mean_norm, std_norm)\n",
    "        predictions7 = znorm_reverse(predictions7a, mean_norm, std_norm)\n",
    "\n",
    "\n",
    "        ##########################\n",
    "\n",
    "        valores_reais = series.tail(12)\n",
    "        valores_reais.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        # mape_result1 = mape(valores_reais, predictions1)\n",
    "        mape_result2 = mape(valores_reais, predictions2)\n",
    "        mape_result3 = mape(valores_reais, predictions3)\n",
    "        mape_result4 = mape(valores_reais, predictions4)\n",
    "        mape_result5 = mape(valores_reais, predictions5)\n",
    "        # mape_result6 = mape(valores_reais, predictions6)\n",
    "        mape_result7 = mape(valores_reais, predictions7)\n",
    "\n",
    "        # pbe_result1 = pbe(valores_reais, predictions1)\n",
    "        pbe_result2 = pbe(valores_reais, predictions2)\n",
    "        pbe_result3 = pbe(valores_reais, predictions3)\n",
    "        pbe_result4 = pbe(valores_reais, predictions4)\n",
    "        pbe_result5 = pbe(valores_reais, predictions5)\n",
    "        # pbe_result6 = pbe(valores_reais, predictions6)\n",
    "        pbe_result7 = pbe(valores_reais, predictions7)\n",
    "\n",
    "        # pocid_result1 = pocid(valores_reais, predictions1)\n",
    "        pocid_result2 = pocid(valores_reais, predictions2)\n",
    "        pocid_result3 = pocid(valores_reais, predictions3)\n",
    "        pocid_result4 = pocid(valores_reais, predictions4)\n",
    "        pocid_result5 = pocid(valores_reais, predictions5)\n",
    "        # pocid_result6 = pocid(valores_reais, predictions6)\n",
    "        pocid_result7 = pocid(valores_reais, predictions7)\n",
    "\n",
    "        # p1 = ', '.join(map(str, predictions1))\n",
    "        p2 = ', '.join(map(str, predictions2))\n",
    "        p3 = ', '.join(map(str, predictions3))\n",
    "        p4 = ', '.join(map(str, predictions4))\n",
    "        p5 = ', '.join(map(str, predictions5))\n",
    "        # p6 = ', '.join(map(str, predictions6))\n",
    "        p7 = ', '.join(map(str, predictions7))\n",
    "\n",
    "        \n",
    "        rows_data = [\n",
    "            # [product,estado,'LR',fd1,mape_result1,pocid_result1,pbe_result1,p1],\n",
    "            [product,estado,'kNN',mape_result2,pocid_result2,pbe_result2,p2],\n",
    "            [product,estado,'XGB',mape_result3,pocid_result3,pbe_result3,p3],\n",
    "            [product,estado,'SVR',mape_result4,pocid_result4,pbe_result4,p4],\n",
    "            [product,estado,'RF',mape_result5,pocid_result5,pbe_result5,p5],\n",
    "            # [product,estado,'MLP',fd6,mape_result6,pocid_result6,pbe_result6,p6],\n",
    "            [product,estado,'LGB',mape_result7,pocid_result7,pbe_result7,p7]             \n",
    "        ]\n",
    "        \n",
    "        # CSV Output VALORES REAIS\n",
    "        with open(f'Metrics_ALL_{product}_{window}_output.csv', 'a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for row_data in rows_data:\n",
    "                writer.writerow(row_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>774</th>\n",
       "      <th>775</th>\n",
       "      <th>776</th>\n",
       "      <th>777</th>\n",
       "      <th>778</th>\n",
       "      <th>779</th>\n",
       "      <th>780</th>\n",
       "      <th>781</th>\n",
       "      <th>782</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.523417</td>\n",
       "      <td>0.259304</td>\n",
       "      <td>-0.903344</td>\n",
       "      <td>-1.213283</td>\n",
       "      <td>-0.377968</td>\n",
       "      <td>-1.048322</td>\n",
       "      <td>-1.185829</td>\n",
       "      <td>0.340350</td>\n",
       "      <td>-1.431287</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240373</td>\n",
       "      <td>0.663710</td>\n",
       "      <td>-2.062046</td>\n",
       "      <td>-1.191792</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.248364</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.784139</td>\n",
       "      <td>-0.097247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.535407</td>\n",
       "      <td>0.270821</td>\n",
       "      <td>-0.905549</td>\n",
       "      <td>-1.213283</td>\n",
       "      <td>-0.465339</td>\n",
       "      <td>-1.045800</td>\n",
       "      <td>-1.185829</td>\n",
       "      <td>0.340350</td>\n",
       "      <td>-1.431287</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240373</td>\n",
       "      <td>0.663710</td>\n",
       "      <td>-0.905042</td>\n",
       "      <td>-0.517680</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.248364</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.767614</td>\n",
       "      <td>-0.020284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.488095</td>\n",
       "      <td>0.223789</td>\n",
       "      <td>-0.919377</td>\n",
       "      <td>-1.213283</td>\n",
       "      <td>-0.120885</td>\n",
       "      <td>-1.064798</td>\n",
       "      <td>0.616258</td>\n",
       "      <td>0.340350</td>\n",
       "      <td>-1.135854</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627686</td>\n",
       "      <td>0.663710</td>\n",
       "      <td>-1.079825</td>\n",
       "      <td>-0.517680</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.248364</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780129</td>\n",
       "      <td>-0.109061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.452404</td>\n",
       "      <td>0.187956</td>\n",
       "      <td>-0.914307</td>\n",
       "      <td>-1.213283</td>\n",
       "      <td>-0.962053</td>\n",
       "      <td>-1.095184</td>\n",
       "      <td>0.616258</td>\n",
       "      <td>0.340350</td>\n",
       "      <td>-1.283570</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.627686</td>\n",
       "      <td>0.663710</td>\n",
       "      <td>-0.810680</td>\n",
       "      <td>-0.263240</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.248364</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.780129</td>\n",
       "      <td>0.243171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.435297</td>\n",
       "      <td>0.172291</td>\n",
       "      <td>-0.898342</td>\n",
       "      <td>-1.213283</td>\n",
       "      <td>-0.962053</td>\n",
       "      <td>-0.612622</td>\n",
       "      <td>0.616258</td>\n",
       "      <td>0.340350</td>\n",
       "      <td>-1.135854</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>...</td>\n",
       "      <td>1.240373</td>\n",
       "      <td>0.663710</td>\n",
       "      <td>0.346325</td>\n",
       "      <td>-0.263240</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.248364</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.811882</td>\n",
       "      <td>-0.201873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>-0.844894</td>\n",
       "      <td>-1.001394</td>\n",
       "      <td>0.755049</td>\n",
       "      <td>-0.267167</td>\n",
       "      <td>-0.465339</td>\n",
       "      <td>0.132790</td>\n",
       "      <td>0.616258</td>\n",
       "      <td>-1.427029</td>\n",
       "      <td>1.301469</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.210376</td>\n",
       "      <td>0.663710</td>\n",
       "      <td>1.328545</td>\n",
       "      <td>1.084985</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.248364</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184777</td>\n",
       "      <td>2.143991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>-0.384026</td>\n",
       "      <td>-1.071411</td>\n",
       "      <td>1.392493</td>\n",
       "      <td>2.098121</td>\n",
       "      <td>0.136198</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>0.616258</td>\n",
       "      <td>-0.837902</td>\n",
       "      <td>1.301469</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.060198</td>\n",
       "      <td>0.663710</td>\n",
       "      <td>0.346325</td>\n",
       "      <td>0.410872</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.248364</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.528702</td>\n",
       "      <td>1.491531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.082933</td>\n",
       "      <td>-1.183579</td>\n",
       "      <td>1.928462</td>\n",
       "      <td>2.571179</td>\n",
       "      <td>0.885179</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>0.616258</td>\n",
       "      <td>-0.248776</td>\n",
       "      <td>1.301469</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.060198</td>\n",
       "      <td>-0.601958</td>\n",
       "      <td>0.077179</td>\n",
       "      <td>0.410872</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.248364</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.786221</td>\n",
       "      <td>1.605760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>2.098482</td>\n",
       "      <td>0.259180</td>\n",
       "      <td>2.269848</td>\n",
       "      <td>2.098121</td>\n",
       "      <td>0.658132</td>\n",
       "      <td>-0.005834</td>\n",
       "      <td>0.616258</td>\n",
       "      <td>-0.248776</td>\n",
       "      <td>1.301469</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.703479</td>\n",
       "      <td>-3.611014</td>\n",
       "      <td>-0.905042</td>\n",
       "      <td>-0.263240</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.248364</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.150710</td>\n",
       "      <td>1.275466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>1.742072</td>\n",
       "      <td>1.968650</td>\n",
       "      <td>2.478369</td>\n",
       "      <td>1.625063</td>\n",
       "      <td>0.510688</td>\n",
       "      <td>-0.001287</td>\n",
       "      <td>0.616258</td>\n",
       "      <td>0.340350</td>\n",
       "      <td>1.301469</td>\n",
       "      <td>-0.310791</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.703479</td>\n",
       "      <td>-3.611014</td>\n",
       "      <td>-1.079825</td>\n",
       "      <td>-0.263240</td>\n",
       "      <td>0.442998</td>\n",
       "      <td>0.248364</td>\n",
       "      <td>0.156307</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.414492</td>\n",
       "      <td>1.154684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows × 1119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.523417  0.259304 -0.903344 -1.213283 -0.377968 -1.048322 -1.185829   \n",
       "1    0.535407  0.270821 -0.905549 -1.213283 -0.465339 -1.045800 -1.185829   \n",
       "2    0.488095  0.223789 -0.919377 -1.213283 -0.120885 -1.064798  0.616258   \n",
       "3    0.452404  0.187956 -0.914307 -1.213283 -0.962053 -1.095184  0.616258   \n",
       "4    0.435297  0.172291 -0.898342 -1.213283 -0.962053 -0.612622  0.616258   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "381 -0.844894 -1.001394  0.755049 -0.267167 -0.465339  0.132790  0.616258   \n",
       "382 -0.384026 -1.071411  1.392493  2.098121  0.136198  0.002436  0.616258   \n",
       "383  0.082933 -1.183579  1.928462  2.571179  0.885179  0.005892  0.616258   \n",
       "384  2.098482  0.259180  2.269848  2.098121  0.658132 -0.005834  0.616258   \n",
       "385  1.742072  1.968650  2.478369  1.625063  0.510688 -0.001287  0.616258   \n",
       "\n",
       "            7         8         9  ...       774       775       776  \\\n",
       "0    0.340350 -1.431287 -0.310791  ...  1.240373  0.663710 -2.062046   \n",
       "1    0.340350 -1.431287 -0.310791  ...  1.240373  0.663710 -0.905042   \n",
       "2    0.340350 -1.135854 -0.310791  ...  0.627686  0.663710 -1.079825   \n",
       "3    0.340350 -1.283570 -0.310791  ...  0.627686  0.663710 -0.810680   \n",
       "4    0.340350 -1.135854 -0.310791  ...  1.240373  0.663710  0.346325   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "381 -1.427029  1.301469 -0.310791  ... -1.210376  0.663710  1.328545   \n",
       "382 -0.837902  1.301469 -0.310791  ... -1.060198  0.663710  0.346325   \n",
       "383 -0.248776  1.301469 -0.310791  ... -1.060198 -0.601958  0.077179   \n",
       "384 -0.248776  1.301469 -0.310791  ... -1.703479 -3.611014 -0.905042   \n",
       "385  0.340350  1.301469 -0.310791  ... -1.703479 -3.611014 -1.079825   \n",
       "\n",
       "          777       778       779       780  781       782         y  \n",
       "0   -1.191792  0.442998  0.248364  0.156307  0.0  1.784139 -0.097247  \n",
       "1   -0.517680  0.442998  0.248364  0.156307  0.0  1.767614 -0.020284  \n",
       "2   -0.517680  0.442998  0.248364  0.156307  0.0  1.780129 -0.109061  \n",
       "3   -0.263240  0.442998  0.248364  0.156307  0.0  1.780129  0.243171  \n",
       "4   -0.263240  0.442998  0.248364  0.156307  0.0  1.811882 -0.201873  \n",
       "..        ...       ...       ...       ...  ...       ...       ...  \n",
       "381  1.084985  0.442998  0.248364  0.156307  0.0  0.184777  2.143991  \n",
       "382  0.410872  0.442998  0.248364  0.156307  0.0  0.528702  1.491531  \n",
       "383  0.410872  0.442998  0.248364  0.156307  0.0  0.786221  1.605760  \n",
       "384 -0.263240  0.442998  0.248364  0.156307  0.0  1.150710  1.275466  \n",
       "385 -0.263240  0.442998  0.248364  0.156307  0.0  1.414492  1.154684  \n",
       "\n",
       "[386 rows x 1119 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_c_znorm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
